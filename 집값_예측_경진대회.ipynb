{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "집값 예측 경진대회.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4BxGKxNvdmGR/MOT7eERM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/younghoonNa/Movie_Review_DACON/blob/main/%EC%A7%91%EA%B0%92_%EC%98%88%EC%B8%A1_%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모두 실행\n"
      ],
      "metadata": {
        "id": "3t6c0vobwL20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 실행에 필요한 코드"
      ],
      "metadata": {
        "id": "3-e9m6zxDpMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 설치\n",
        "!pip install gdrive_dataset"
      ],
      "metadata": {
        "id": "mRx4BKF_-nGl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b204f796-62b0-45c9-88c7-beeb2c183ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gdrive_dataset\n",
            "  Downloading gdrive_dataset-0.0.5-py3-none-any.whl (2.1 kB)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from gdrive_dataset) (0.4)\n",
            "Installing collected packages: gdrive-dataset\n",
            "Successfully installed gdrive-dataset-0.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD5-fiY-cvua",
        "outputId": "34a3a673-2d16-42a2-caea-209ed3871005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.4-cp37-none-manylinux1_x86_64.whl (76.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.1 MB 49 kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install ngboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9woQJAmefvME",
        "outputId": "cc908d84-cba1-4349-becc-b83d5c66434d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ngboost\n",
            "  Downloading ngboost-0.3.12-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.7/dist-packages (from ngboost) (1.0.2)\n",
            "Collecting lifelines>=0.25\n",
            "  Downloading lifelines-0.26.4-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3 in /usr/local/lib/python3.7/dist-packages (from ngboost) (1.4.1)\n",
            "Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.7/dist-packages (from ngboost) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from ngboost) (1.19.5)\n",
            "Requirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from lifelines>=0.25->ngboost) (1.3)\n",
            "Collecting autograd-gamma>=0.3\n",
            "  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n",
            "Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.7/dist-packages (from lifelines>=0.25->ngboost) (3.2.2)\n",
            "Collecting formulaic<0.3,>=0.2.2\n",
            "  Downloading formulaic-0.2.4-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from lifelines>=0.25->ngboost) (1.1.5)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->lifelines>=0.25->ngboost) (0.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines>=0.25->ngboost) (1.13.3)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from formulaic<0.3,>=0.2.2->lifelines>=0.25->ngboost) (0.8.1)\n",
            "Collecting interface-meta>=1.2\n",
            "  Downloading interface_meta-1.2.4-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (3.0.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->lifelines>=0.25->ngboost) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0->lifelines>=0.25->ngboost) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->ngboost) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->ngboost) (3.0.0)\n",
            "Building wheels for collected packages: autograd-gamma\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4048 sha256=ddeb2f04ecb456288bbbd8a78319f73b532332cc2d97b7b906142489f3baf27c\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/01/ee/1331593abb5725ff7d8c1333aee93a50a1c29d6ddda9665c9f\n",
            "Successfully built autograd-gamma\n",
            "Installing collected packages: interface-meta, formulaic, autograd-gamma, lifelines, ngboost\n",
            "Successfully installed autograd-gamma-0.5.0 formulaic-0.2.4 interface-meta-1.2.4 lifelines-0.26.4 ngboost-0.3.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://drive.google.com/file/d/1korokEjnq76DP_igBYoukf86tpE5RIui/view\n",
        "from gdrivedataset import loader\n",
        "\n",
        "file_id = \"1korokEjnq76DP_igBYoukf86tpE5RIui\"\n",
        "loader.load_from_google_drive(file_id)"
      ],
      "metadata": {
        "id": "j5O2lO_x-qOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18572b7c-332e-4515-eae7-67091655cdda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1korokEjnq76DP_igBYoukf86tpE5RIui into ./dataset.zip... Done.\n",
            "========== files ============\n",
            "\n",
            "data/train.csv\n",
            "data/test.csv\n",
            "data/sample_submission.csv\n",
            "\n",
            "=============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def NMAE(true, pred):\n",
        "    mae = np.mean(np.abs(true-pred))\n",
        "    score = mae / np.mean(np.abs(true))\n",
        "    return score"
      ],
      "metadata": {
        "id": "o9Lj8rm_DSiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#기본 모듈은 numpy 그리고 pandas 사용.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer,RobustScaler\n",
        "from scipy.stats import randint, uniform\n",
        "\n",
        "#분류/Classifier 사용에 필요한 모델 import \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#Regressor에 필요한 모델 \n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from ngboost import NGBRegressor\n",
        "from sklearn.linear_model import LassoLars\n"
      ],
      "metadata": {
        "id": "gUnvGPJH_EzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시작"
      ],
      "metadata": {
        "id": "3E173LB9D158"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Test 데이터 load"
      ],
      "metadata": {
        "id": "KEowzniP_l5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/data/train.csv')\n",
        "train = train.iloc[: ,1:]\n",
        "train"
      ],
      "metadata": {
        "id": "5PvSN19A-auq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "4068137e-3a18-45a1-cc13-c138535b4713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a8cdd745-ab4b-4d33-8d4c-875d64b6ed0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Overall Qual</th>\n",
              "      <th>Gr Liv Area</th>\n",
              "      <th>Exter Qual</th>\n",
              "      <th>Garage Cars</th>\n",
              "      <th>Garage Area</th>\n",
              "      <th>Kitchen Qual</th>\n",
              "      <th>Total Bsmt SF</th>\n",
              "      <th>1st Flr SF</th>\n",
              "      <th>Bsmt Qual</th>\n",
              "      <th>Full Bath</th>\n",
              "      <th>Year Built</th>\n",
              "      <th>Year Remod/Add</th>\n",
              "      <th>Garage Yr Blt</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10</td>\n",
              "      <td>2392</td>\n",
              "      <td>Ex</td>\n",
              "      <td>3</td>\n",
              "      <td>968</td>\n",
              "      <td>Ex</td>\n",
              "      <td>2392</td>\n",
              "      <td>2392</td>\n",
              "      <td>Ex</td>\n",
              "      <td>2</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>386250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>1352</td>\n",
              "      <td>Gd</td>\n",
              "      <td>2</td>\n",
              "      <td>466</td>\n",
              "      <td>Gd</td>\n",
              "      <td>1352</td>\n",
              "      <td>1352</td>\n",
              "      <td>Ex</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>2007</td>\n",
              "      <td>2006</td>\n",
              "      <td>194000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>900</td>\n",
              "      <td>TA</td>\n",
              "      <td>1</td>\n",
              "      <td>288</td>\n",
              "      <td>TA</td>\n",
              "      <td>864</td>\n",
              "      <td>900</td>\n",
              "      <td>TA</td>\n",
              "      <td>1</td>\n",
              "      <td>1967</td>\n",
              "      <td>1967</td>\n",
              "      <td>1967</td>\n",
              "      <td>123000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>1174</td>\n",
              "      <td>TA</td>\n",
              "      <td>2</td>\n",
              "      <td>576</td>\n",
              "      <td>Gd</td>\n",
              "      <td>680</td>\n",
              "      <td>680</td>\n",
              "      <td>TA</td>\n",
              "      <td>1</td>\n",
              "      <td>1900</td>\n",
              "      <td>2006</td>\n",
              "      <td>2000</td>\n",
              "      <td>135000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>1958</td>\n",
              "      <td>Gd</td>\n",
              "      <td>3</td>\n",
              "      <td>936</td>\n",
              "      <td>Gd</td>\n",
              "      <td>1026</td>\n",
              "      <td>1026</td>\n",
              "      <td>Gd</td>\n",
              "      <td>2</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345</th>\n",
              "      <td>6</td>\n",
              "      <td>1756</td>\n",
              "      <td>Gd</td>\n",
              "      <td>2</td>\n",
              "      <td>422</td>\n",
              "      <td>TA</td>\n",
              "      <td>872</td>\n",
              "      <td>888</td>\n",
              "      <td>Ex</td>\n",
              "      <td>2</td>\n",
              "      <td>1996</td>\n",
              "      <td>1997</td>\n",
              "      <td>1996</td>\n",
              "      <td>204000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1346</th>\n",
              "      <td>9</td>\n",
              "      <td>2748</td>\n",
              "      <td>Gd</td>\n",
              "      <td>3</td>\n",
              "      <td>850</td>\n",
              "      <td>Ex</td>\n",
              "      <td>1850</td>\n",
              "      <td>1850</td>\n",
              "      <td>Ex</td>\n",
              "      <td>2</td>\n",
              "      <td>2006</td>\n",
              "      <td>2006</td>\n",
              "      <td>2006</td>\n",
              "      <td>390000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1347</th>\n",
              "      <td>5</td>\n",
              "      <td>1214</td>\n",
              "      <td>TA</td>\n",
              "      <td>1</td>\n",
              "      <td>318</td>\n",
              "      <td>TA</td>\n",
              "      <td>1214</td>\n",
              "      <td>1214</td>\n",
              "      <td>TA</td>\n",
              "      <td>2</td>\n",
              "      <td>1967</td>\n",
              "      <td>1967</td>\n",
              "      <td>1967</td>\n",
              "      <td>143000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1348</th>\n",
              "      <td>5</td>\n",
              "      <td>894</td>\n",
              "      <td>TA</td>\n",
              "      <td>2</td>\n",
              "      <td>440</td>\n",
              "      <td>TA</td>\n",
              "      <td>864</td>\n",
              "      <td>894</td>\n",
              "      <td>Gd</td>\n",
              "      <td>1</td>\n",
              "      <td>1974</td>\n",
              "      <td>1974</td>\n",
              "      <td>1974</td>\n",
              "      <td>131000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>5</td>\n",
              "      <td>907</td>\n",
              "      <td>TA</td>\n",
              "      <td>1</td>\n",
              "      <td>343</td>\n",
              "      <td>TA</td>\n",
              "      <td>907</td>\n",
              "      <td>907</td>\n",
              "      <td>Gd</td>\n",
              "      <td>1</td>\n",
              "      <td>1978</td>\n",
              "      <td>1978</td>\n",
              "      <td>1978</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1350 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8cdd745-ab4b-4d33-8d4c-875d64b6ed0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8cdd745-ab4b-4d33-8d4c-875d64b6ed0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8cdd745-ab4b-4d33-8d4c-875d64b6ed0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      Overall Qual  Gr Liv Area  ... Garage Yr Blt  target\n",
              "0               10         2392  ...          2003  386250\n",
              "1                7         1352  ...          2006  194000\n",
              "2                5          900  ...          1967  123000\n",
              "3                5         1174  ...          2000  135000\n",
              "4                7         1958  ...          2005  250000\n",
              "...            ...          ...  ...           ...     ...\n",
              "1345             6         1756  ...          1996  204000\n",
              "1346             9         2748  ...          2006  390000\n",
              "1347             5         1214  ...          1967  143000\n",
              "1348             5          894  ...          1974  131000\n",
              "1349             5          907  ...          1978  140000\n",
              "\n",
              "[1350 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('/content/data/test.csv')\n",
        "test"
      ],
      "metadata": {
        "id": "qFL0ewKy_Dmr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "7c38d734-cefe-4937-b3e2-000562a4827f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ad4bc40a-2db2-4bb8-95bf-1e9a342cc40e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Overall Qual</th>\n",
              "      <th>Gr Liv Area</th>\n",
              "      <th>Exter Qual</th>\n",
              "      <th>Garage Cars</th>\n",
              "      <th>Garage Area</th>\n",
              "      <th>Kitchen Qual</th>\n",
              "      <th>Total Bsmt SF</th>\n",
              "      <th>1st Flr SF</th>\n",
              "      <th>Bsmt Qual</th>\n",
              "      <th>Full Bath</th>\n",
              "      <th>Year Built</th>\n",
              "      <th>Year Remod/Add</th>\n",
              "      <th>Garage Yr Blt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1800</td>\n",
              "      <td>Gd</td>\n",
              "      <td>2</td>\n",
              "      <td>702</td>\n",
              "      <td>Ex</td>\n",
              "      <td>1800</td>\n",
              "      <td>1800</td>\n",
              "      <td>Ex</td>\n",
              "      <td>2</td>\n",
              "      <td>2007</td>\n",
              "      <td>2007</td>\n",
              "      <td>2007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>1082</td>\n",
              "      <td>TA</td>\n",
              "      <td>1</td>\n",
              "      <td>240</td>\n",
              "      <td>TA</td>\n",
              "      <td>1082</td>\n",
              "      <td>1082</td>\n",
              "      <td>TA</td>\n",
              "      <td>1</td>\n",
              "      <td>1948</td>\n",
              "      <td>1950</td>\n",
              "      <td>1948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>1573</td>\n",
              "      <td>Gd</td>\n",
              "      <td>2</td>\n",
              "      <td>440</td>\n",
              "      <td>Gd</td>\n",
              "      <td>756</td>\n",
              "      <td>769</td>\n",
              "      <td>Gd</td>\n",
              "      <td>2</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>2443</td>\n",
              "      <td>Gd</td>\n",
              "      <td>3</td>\n",
              "      <td>744</td>\n",
              "      <td>Gd</td>\n",
              "      <td>1158</td>\n",
              "      <td>1158</td>\n",
              "      <td>Gd</td>\n",
              "      <td>2</td>\n",
              "      <td>2004</td>\n",
              "      <td>2004</td>\n",
              "      <td>2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1040</td>\n",
              "      <td>TA</td>\n",
              "      <td>2</td>\n",
              "      <td>686</td>\n",
              "      <td>TA</td>\n",
              "      <td>1040</td>\n",
              "      <td>1040</td>\n",
              "      <td>TA</td>\n",
              "      <td>1</td>\n",
              "      <td>1968</td>\n",
              "      <td>1968</td>\n",
              "      <td>1991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345</th>\n",
              "      <td>1346</td>\n",
              "      <td>8</td>\n",
              "      <td>1932</td>\n",
              "      <td>Ex</td>\n",
              "      <td>3</td>\n",
              "      <td>774</td>\n",
              "      <td>Ex</td>\n",
              "      <td>1932</td>\n",
              "      <td>1932</td>\n",
              "      <td>Ex</td>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>2008</td>\n",
              "      <td>2008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1346</th>\n",
              "      <td>1347</td>\n",
              "      <td>5</td>\n",
              "      <td>912</td>\n",
              "      <td>TA</td>\n",
              "      <td>1</td>\n",
              "      <td>288</td>\n",
              "      <td>TA</td>\n",
              "      <td>912</td>\n",
              "      <td>912</td>\n",
              "      <td>TA</td>\n",
              "      <td>1</td>\n",
              "      <td>1964</td>\n",
              "      <td>1964</td>\n",
              "      <td>1964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1347</th>\n",
              "      <td>1348</td>\n",
              "      <td>4</td>\n",
              "      <td>861</td>\n",
              "      <td>TA</td>\n",
              "      <td>2</td>\n",
              "      <td>288</td>\n",
              "      <td>TA</td>\n",
              "      <td>861</td>\n",
              "      <td>861</td>\n",
              "      <td>Fa</td>\n",
              "      <td>1</td>\n",
              "      <td>1920</td>\n",
              "      <td>1950</td>\n",
              "      <td>1920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1348</th>\n",
              "      <td>1349</td>\n",
              "      <td>5</td>\n",
              "      <td>1430</td>\n",
              "      <td>TA</td>\n",
              "      <td>2</td>\n",
              "      <td>624</td>\n",
              "      <td>Gd</td>\n",
              "      <td>1430</td>\n",
              "      <td>1430</td>\n",
              "      <td>Ex</td>\n",
              "      <td>2</td>\n",
              "      <td>2004</td>\n",
              "      <td>2005</td>\n",
              "      <td>2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>1350</td>\n",
              "      <td>5</td>\n",
              "      <td>2337</td>\n",
              "      <td>TA</td>\n",
              "      <td>2</td>\n",
              "      <td>560</td>\n",
              "      <td>TA</td>\n",
              "      <td>662</td>\n",
              "      <td>1422</td>\n",
              "      <td>TA</td>\n",
              "      <td>2</td>\n",
              "      <td>1900</td>\n",
              "      <td>1950</td>\n",
              "      <td>1945</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1350 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad4bc40a-2db2-4bb8-95bf-1e9a342cc40e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad4bc40a-2db2-4bb8-95bf-1e9a342cc40e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad4bc40a-2db2-4bb8-95bf-1e9a342cc40e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id  Overall Qual  ...  Year Remod/Add Garage Yr Blt\n",
              "0        1             9  ...            2007          2007\n",
              "1        2             6  ...            1950          1948\n",
              "2        3             6  ...            2000          2000\n",
              "3        4             6  ...            2004          2004\n",
              "4        5             5  ...            1968          1991\n",
              "...    ...           ...  ...             ...           ...\n",
              "1345  1346             8  ...            2008          2008\n",
              "1346  1347             5  ...            1964          1964\n",
              "1347  1348             4  ...            1950          1920\n",
              "1348  1349             5  ...            2005          2004\n",
              "1349  1350             5  ...            1950          1945\n",
              "\n",
              "[1350 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv('/content/data/sample_submission.csv')\n",
        "sample_submission"
      ],
      "metadata": {
        "id": "sw8gImGC_LHf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "c1f9d56b-b436-41ee-c399-27f163927ea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f5ecbc89-c579-4239-8f4d-b9b3cbff4396\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345</th>\n",
              "      <td>1346</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1346</th>\n",
              "      <td>1347</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1347</th>\n",
              "      <td>1348</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1348</th>\n",
              "      <td>1349</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>1350</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1350 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5ecbc89-c579-4239-8f4d-b9b3cbff4396')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5ecbc89-c579-4239-8f4d-b9b3cbff4396 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5ecbc89-c579-4239-8f4d-b9b3cbff4396');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id  target\n",
              "0        1       0\n",
              "1        2       0\n",
              "2        3       0\n",
              "3        4       0\n",
              "4        5       0\n",
              "...    ...     ...\n",
              "1345  1346       0\n",
              "1346  1347       0\n",
              "1347  1348       0\n",
              "1348  1349       0\n",
              "1349  1350       0\n",
              "\n",
              "[1350 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 결측값 및 중복값 제거"
      ],
      "metadata": {
        "id": "EtocwG8n8B8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.isna().sum()"
      ],
      "metadata": {
        "id": "AOJuKYcK_OPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294e24fd-ffa6-4dd7-b1aa-8029a039bf66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Overall Qual      0\n",
              "Gr Liv Area       0\n",
              "Exter Qual        0\n",
              "Garage Cars       0\n",
              "Garage Area       0\n",
              "Kitchen Qual      0\n",
              "Total Bsmt SF     0\n",
              "1st Flr SF        0\n",
              "Bsmt Qual         0\n",
              "Full Bath         0\n",
              "Year Built        0\n",
              "Year Remod/Add    0\n",
              "Garage Yr Blt     0\n",
              "target            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.isna().sum()"
      ],
      "metadata": {
        "id": "nFj5SNqn_W7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23f9f0a6-5b9f-4c50-ccec-2be2b65def52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                0\n",
              "Overall Qual      0\n",
              "Gr Liv Area       0\n",
              "Exter Qual        0\n",
              "Garage Cars       0\n",
              "Garage Area       0\n",
              "Kitchen Qual      0\n",
              "Total Bsmt SF     0\n",
              "1st Flr SF        0\n",
              "Bsmt Qual         0\n",
              "Full Bath         0\n",
              "Year Built        0\n",
              "Year Remod/Add    0\n",
              "Garage Yr Blt     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 중복값 제거\n",
        "print(\"제거 전 :\", train.shape)\n",
        "train = train.drop_duplicates()\n",
        "print(\"제거 후 :\", train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUbuuYoYZpKE",
        "outputId": "75a041f1-7d72-4cd5-96dd-1561bf562880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "제거 전 : (1350, 14)\n",
            "제거 후 : (1349, 14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 특성 분류"
      ],
      "metadata": {
        "id": "YsfMA_jf_p9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()\n",
        "# id : 데이터 고유 id\n",
        "# OverallQual : 전반적 재료와 마감 품질\n",
        "# YearBuilt : 완공 연도\n",
        "# YearRemodAdd : 리모델링 연도\n",
        "# ExterQual : 외관 재료 품질\n",
        "# BsmtQual : 지하실 높이\n",
        "# TotalBsmtSF : 지하실 면적 \n",
        "# 1stFlrSF : 1층 면적 \n",
        "# GrLivArea : 지상층 생활 면적\n",
        "# FullBath : 지상층 화장실 개수 \n",
        "# KitchenQual : 부억 품질 \n",
        "# GarageYrBlt : 차고 완공 연도\n",
        "# GarageCars: 차고 자리 개수\n",
        "# GarageArea: 차고 면적 \n",
        "# target : 집값(달러 단위)"
      ],
      "metadata": {
        "id": "DsEiWlSgAZoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f815a99-a94f-4207-f71c-6722aff69db8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1349 entries, 0 to 1349\n",
            "Data columns (total 14 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   Overall Qual    1349 non-null   int64 \n",
            " 1   Gr Liv Area     1349 non-null   int64 \n",
            " 2   Exter Qual      1349 non-null   object\n",
            " 3   Garage Cars     1349 non-null   int64 \n",
            " 4   Garage Area     1349 non-null   int64 \n",
            " 5   Kitchen Qual    1349 non-null   object\n",
            " 6   Total Bsmt SF   1349 non-null   int64 \n",
            " 7   1st Flr SF      1349 non-null   int64 \n",
            " 8   Bsmt Qual       1349 non-null   object\n",
            " 9   Full Bath       1349 non-null   int64 \n",
            " 10  Year Built      1349 non-null   int64 \n",
            " 11  Year Remod/Add  1349 non-null   int64 \n",
            " 12  Garage Yr Blt   1349 non-null   int64 \n",
            " 13  target          1349 non-null   int64 \n",
            "dtypes: int64(11), object(3)\n",
            "memory usage: 158.1+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 범주형 데이터 처리하기\n",
        "\n",
        "1. 범주형 데이터 Exter Qual , Kitchen Qual , Bsmt Qual 처리하기\n",
        "2. Ex -> 5, Gd-> 4, Ta->3, Fa->2, Po ->1"
      ],
      "metadata": {
        "id": "LLmZT5m36FyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exter Qual, Kitchen Qual, Bsmt Qual"
      ],
      "metadata": {
        "id": "bfvS2n1k8MfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['Exter Qual'].value_counts()"
      ],
      "metadata": {
        "id": "E-sLtHbZAXrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93803c23-a88d-4128-b36c-865719e40dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TA    807\n",
              "Gd    485\n",
              "Ex     49\n",
              "Fa      8\n",
              "Name: Exter Qual, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['Kitchen Qual'].value_counts()"
      ],
      "metadata": {
        "id": "C0hC4P9sG-yN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c80e39-e76a-45b2-cb3d-97ca3d9bc2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TA    659\n",
              "Gd    560\n",
              "Ex    107\n",
              "Fa     23\n",
              "Name: Kitchen Qual, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['Bsmt Qual'].value_counts()"
      ],
      "metadata": {
        "id": "zHtIVef9G5st",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f26c398f-f2aa-4edf-a92e-8f733777a592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TA    605\n",
              "Gd    582\n",
              "Ex    133\n",
              "Fa     28\n",
              "Po      1\n",
              "Name: Bsmt Qual, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 범주형 데이터 -> 각 각 값에 맞는 숫자로 변환."
      ],
      "metadata": {
        "id": "ofJl4xil81PM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#apply 함수 사용.\n",
        "def trans(x):\n",
        "  if x == \"Ex\": return 5\n",
        "  elif x=='Gd' : return 4\n",
        "  elif x=='TA' : return 3\n",
        "  elif x=='Fa' : return 2\n",
        "  elif x=='Po' : return 1"
      ],
      "metadata": {
        "id": "oc-9ij5jAz0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['Exter Qual mapping'] = train['Exter Qual'].apply(trans)\n",
        "train['Exter Qual mapping'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RUIPZBJ9BEr",
        "outputId": "15039454-f20b-4ab4-919b-be7eb20ad970"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    807\n",
              "4    485\n",
              "5     49\n",
              "2      8\n",
              "Name: Exter Qual mapping, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['Kitchen Qual mapping'] = train['Kitchen Qual'].apply(trans)\n",
        "train['Kitchen Qual mapping'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EZK3YBHA4tM",
        "outputId": "48c98cf0-05bf-43a4-90ba-e4a8dba183db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    659\n",
              "4    560\n",
              "5    107\n",
              "2     23\n",
              "Name: Kitchen Qual mapping, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['Bsmt Qual mapping'] = train['Bsmt Qual'].apply(trans)\n",
        "train['Bsmt Qual mapping'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7mKeq4oA5Bt",
        "outputId": "aea2e328-11be-47a3-ab66-1875c3f80e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    605\n",
              "4    582\n",
              "5    133\n",
              "2     28\n",
              "1      1\n",
              "Name: Bsmt Qual mapping, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test 데이터도 범주형 데이터 처리"
      ],
      "metadata": {
        "id": "s8UwF0Ry8agc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test['Exter Qual'].value_counts(), test['Kitchen Qual'].value_counts(), test['Bsmt Qual'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDsRJBG9DEal",
        "outputId": "6defb439-6667-4a5f-b581-664b5cf07ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TA    794\n",
              " Gd    489\n",
              " Ex     58\n",
              " Fa      9\n",
              " Name: Exter Qual, dtype: int64, TA    666\n",
              " Gd    566\n",
              " Ex     94\n",
              " Fa     23\n",
              " Po      1\n",
              " Name: Kitchen Qual, dtype: int64, Gd    597\n",
              " TA    582\n",
              " Ex    124\n",
              " Fa     46\n",
              " Po      1\n",
              " Name: Bsmt Qual, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['Exter Qual mapping'] = test['Exter Qual'].apply(trans)\n",
        "test['Exter Qual mapping'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iErIajoHC8bR",
        "outputId": "395551d7-3b5f-46f8-fba1-afc3e0453774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    794\n",
              "4    489\n",
              "5     58\n",
              "2      9\n",
              "Name: Exter Qual mapping, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['Kitchen Qual mapping'] = test['Kitchen Qual'].apply(trans)\n",
        "test['Kitchen Qual mapping'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnCaPGt7C_mZ",
        "outputId": "99bb2ddf-3b66-4000-a967-f08137b5d2ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    666\n",
              "4    566\n",
              "5     94\n",
              "2     23\n",
              "1      1\n",
              "Name: Kitchen Qual mapping, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test['Bsmt Qual mapping'] = test['Bsmt Qual'].apply(trans)\n",
        "test['Bsmt Qual mapping'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcOYt2TIC_g7",
        "outputId": "0bba3b10-f986-4a15-ccd4-9d4b65ded7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    597\n",
              "3    582\n",
              "5    124\n",
              "2     46\n",
              "1      1\n",
              "Name: Bsmt Qual mapping, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 서로 상관관계가 높은 train['1st Flr SF'] + train['Total Bsmt SF'] 하나로 합쳐줌."
      ],
      "metadata": {
        "id": "psQbUCSIDWKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train['sum of house'] = train['1st Flr SF'] + train['Total Bsmt SF']\n",
        "# test['sum of house'] = test['1st Flr SF'] + test['Total Bsmt SF']\n",
        "\n",
        "# train['sum of house'] , test['sum of house']"
      ],
      "metadata": {
        "id": "G8WVPG8L8d2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ex, TA Gd 사용 O X -> 점수로 변환. // 따라서 주석 처리 "
      ],
      "metadata": {
        "id": "G7DUJL7-Bbpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 다른 인코딩 방법"
      ],
      "metadata": {
        "id": "0VJvr4uxrHcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cat_cols = ['Exter Qual', 'Kitchen Qual', 'Bsmt Qual']"
      ],
      "metadata": {
        "id": "1StQ6_xMrJ75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for c in cat_cols :\n",
        "#     ord_df = train.groupby(c).target.median().reset_index(name = f'ord_{c}')\n",
        "#     train = pd.merge(train, ord_df, how = 'left')\n",
        "#     test = pd.merge(test, ord_df, how = 'left')"
      ],
      "metadata": {
        "id": "Z2jj8d-arMZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train"
      ],
      "metadata": {
        "id": "8u0BRtccrNHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Exter Qual 사용여부"
      ],
      "metadata": {
        "id": "VeKSj4PM1Ss6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train['Use EQ Ex'] = train[['Exter Qual', 'Kitchen Qual', 'Bsmt Qual']].apply(lambda x: (0, 1)\\\n",
        "#                                           [x['Exter Qual'] == 'Ex' or x['Kitchen Qual'] == 'Ex' or x['Bsmt Qual'] == 'Ex'] , axis=1)\n",
        "\n",
        "# train['Use EQ Ex'].value_counts()"
      ],
      "metadata": {
        "id": "BBh_WEcn1rLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train['Use EQ Ex'] = train[['Exter Qual']].apply(lambda x: (0, 1)\\\n",
        "#                                           [x['Exter Qual'] == 'TA'], axis=1)\n",
        "\n",
        "# train['Use EQ Ex'].value_counts()"
      ],
      "metadata": {
        "id": "GitMmMml1sIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Kitchen Qual 사용여부"
      ],
      "metadata": {
        "id": "21LVqOvc1XND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train.loc[train['Kitchen Qual'] == 'TA', :]['target'].mean() , train.loc[train['Kitchen Qual'] != 'TA', :]['target'].mean()"
      ],
      "metadata": {
        "id": "Fsf0VOA01PLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.loc[train['Kitchen Qual'] == 'Gd', :]['target'].mean() , train.loc[train['Kitchen Qual'] != 'Gd', :]['target'].mean()"
      ],
      "metadata": {
        "id": "7OlVPLRq1QN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.loc[train['Kitchen Qual'] == 'Ex', :]['target'].mean() , train.loc[train['Kitchen Qual'] != 'Ex', :]['target'].mean()"
      ],
      "metadata": {
        "id": "H6QoAC921QC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.loc[train['Kitchen Qual'] == 'Fa', :]['target'].mean() , train.loc[train['Kitchen Qual'] != 'Fa', :]['target'].mean()"
      ],
      "metadata": {
        "id": "5uYCGjgW1P3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train['Use KQ Ex'] = train[['Kitchen Qual']].apply(lambda x: (0, 1)\\\n",
        "                                          # [x['Kitchen Qual'] == 'Ex'], axis=1)\n",
        "\n",
        "# train['Use KQ Ex'].value_counts()"
      ],
      "metadata": {
        "id": "HYKUnnJ-1xwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Bsmt Qual"
      ],
      "metadata": {
        "id": "fHY4dG4P19iG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train['Use Gd'] = train[['Exter Qual', 'Kitchen Qual', 'Bsmt Qual']].apply(lambda x: (0, 1)\\\n",
        "#                                           [x['Exter Qual'] == 'Gd' or x['Kitchen Qual'] == 'Gd' or x['Bsmt Qual'] == 'Gd'], axis=1)\n",
        "\n",
        "# train['Use Gd'].value_counts()"
      ],
      "metadata": {
        "id": "LwNgi0iXK13v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test['Use Gd'] = test[['Exter Qual', 'Kitchen Qual', 'Bsmt Qual']].apply(lambda x: (0, 1)\\\n",
        "#                                           [x['Exter Qual'] == 'Gd' or x['Kitchen Qual'] == 'Gd' or x['Bsmt Qual'] == 'Gd'], axis=1)\n",
        "\n",
        "# test['Use Gd'].value_counts()"
      ],
      "metadata": {
        "id": "M3dY281naWAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train['Use Fa'] = train[['Exter Qual', 'Kitchen Qual', 'Bsmt Qual']].apply(lambda x: (0, 1)\\\n",
        "#                                           [x['Exter Qual'] == 'Fa' or x['Kitchen Qual'] == 'Fa' or x['Bsmt Qual'] == 'Fa'], axis=1)\n",
        "\n",
        "# train['Use Fa'].value_counts()"
      ],
      "metadata": {
        "id": "zSpBbV0qAz1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train['Use KQ Ex'] = train[['Exter Qual', 'Kitchen Qual', 'Bsmt Qual']].apply(lambda x: (0, 1)\\\n",
        "#                                           [x['Kitchen Qual'] == 'Ex'], axis=1)\n",
        "\n",
        "# train['Use KQ Ex'].value_counts()"
      ],
      "metadata": {
        "id": "Ye_4Fvij1JZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train['Use EQ Ex'] = train[['Exter Qual', 'Kitchen Qual', 'Bsmt Qual']].apply(lambda x: (0, 1)\\\n",
        "#                                           [x['Exter Qual'] == 'Ex'], axis=1)\n",
        "\n",
        "# train['Use EQ Ex'].value_counts()"
      ],
      "metadata": {
        "id": "J9XsWvsE0heG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train['Use EQ Ex']"
      ],
      "metadata": {
        "id": "k06bSBdMTLqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 인코딩."
      ],
      "metadata": {
        "id": "4XqAtUIqxPyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# eq = pd.get_dummies(train['Exter Qual'], prefix='EQ', prefix_sep='_')\n",
        "# kq = pd.get_dummies(train['Kitchen Qual'],prefix='KQ', prefix_sep='_')\n",
        "# bq = pd.get_dummies(train['Bsmt Qual'],prefix='BQ', prefix_sep='_')\n",
        "\n",
        "# train = pd.concat((train, eq), axis=1)\n",
        "# train = pd.concat((train, kq), axis=1)\n",
        "# train = pd.concat((train, bq), axis=1)\n",
        "\n",
        "# train.head()"
      ],
      "metadata": {
        "id": "DSggwLt3xR6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eq = pd.get_dummies(test['Exter Qual'], prefix='EQ', prefix_sep='_')\n",
        "# kq = pd.get_dummies(test['Kitchen Qual'],prefix='KQ', prefix_sep='_')\n",
        "# bq = pd.get_dummies(test['Bsmt Qual'],prefix='BQ', prefix_sep='_')\n",
        "\n",
        "# test = pd.concat((test, eq), axis=1)\n",
        "# test = pd.concat((test, kq), axis=1)\n",
        "# test = pd.concat((test, bq), axis=1)\n",
        "\n",
        "# test.head()"
      ],
      "metadata": {
        "id": "N7E_Dr_E2Aik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Garage Yr blt 2200년 수정"
      ],
      "metadata": {
        "id": "8xUzBgxYHZro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.loc[train['Garage Yr Blt']> 2050, 'Garage Yr Blt'] = 2007"
      ],
      "metadata": {
        "id": "rZ3CoqFhHgxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdaaba6a-c2c5-444c-ec70-bcd487ce9673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1763: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GroupBy를 통한 새로운 특성을 만들어보자\n",
        "\n",
        "0.   id              1350 non-null   int64 \n",
        "1.   Overall Qual    1350 non-null   int64 \n",
        "2.  Gr Liv Area     1350 non-null   int64 \n",
        "3. Exter Qual      1350 non-null   object\n",
        "4.   Garage Cars     1350 non-null   int64 \n",
        "5.  Garage Area     1350 non-null   int64 \n",
        "6.   Kitchen Qual    1350 non-null   object\n",
        "7.   Total Bsmt SF   1350 non-null   int64 \n",
        "8.   1st Flr SF      1350 non-null   int64 \n",
        "9.   Bsmt Qual       1350 non-null   object\n",
        "10.  Full Bath       1350 non-null   int64 \n",
        "11.  Year Built      1350 non-null   int64 \n",
        "12.  Year Remod/Add  1350 non-null   int64 \n",
        "13.  Garage Yr Blt   1350 non-null   int64 \n",
        "14.  target          1350 non-null   int64 "
      ],
      "metadata": {
        "id": "seJiROQe5dOB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train.loc[:, 'car/area'] = train.loc[:, 'Garage Area'] * train.loc[:, 'Garage Cars']\n",
        "# train['car/area'] = np.round(train['car/area'])"
      ],
      "metadata": {
        "id": "9wm3ACFn8f4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_eng(data_):\n",
        "  data = data_.copy()\n",
        "  data['Year Gap Remod'] = data['Year Remod/Add'] - data['Year Built']\n",
        "  data['Car Area'] = data['Garage Area'] / data['Garage Cars']\n",
        "  data['2nd flr SF'] = data['Gr Liv Area'] - data['1st Flr SF']\n",
        "  data['2nd flr'] = data['2nd flr SF'].apply(lambda x : 1 if x > 0 else 0)\n",
        "  data['Total SF'] = data[['Gr Liv Area',\"Garage Area\", \"Total Bsmt SF\"]].sum(axis=1)\n",
        "  data['Sum Qual'] = data[[\"Exter Qual\", \"Kitchen Qual\", \"Overall Qual\"]].sum(axis=1)\n",
        "  data['Garage InOut'] = data.apply(lambda x : 1 if x['Gr Liv Area'] != x['1st Flr SF'] else 0, axis=1)\n",
        "  return data\n",
        "\n",
        "train = feature_eng(train)\n",
        "test = feature_eng(test)"
      ],
      "metadata": {
        "id": "0B-yYuwqaaad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # train['sum of house'] = train['1st Flr SF'] + train['Total Bsmt SF'] \n",
        "# # test['sum of house'] = test['1st Flr SF'] + test['Total Bsmt SF']\n",
        "# train['total of house'] = train['sum of house'] + train['Garage Area']\n",
        "# test['total of house'] = test['sum of house'] + test['Garage Area']\n",
        "# train['total of house']"
      ],
      "metadata": {
        "id": "dqhJyODqAxiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.loc[:, 'area/3.3'] = train.loc[:, 'Gr Liv Area'] / 3.3\n",
        "# test.loc[:, 'area/3.3'] = test.loc[:, 'Gr Liv Area'] / 3.3\n",
        "\n",
        "# train['area/3.3'] =  np.round(train['area/3.3'])\n",
        "# test['area/3.3'] =  np.round(test['area/3.3'])"
      ],
      "metadata": {
        "id": "UEHFaoMK_Z2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.loc[train['target'] < 100000, :]"
      ],
      "metadata": {
        "id": "ECjyOPnj84I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.loc[train['Overall Qual'] < 7, 'target'].mean()"
      ],
      "metadata": {
        "id": "zSvt9ZPb5hb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.loc[train['Overall Qual'] >= 10, 'target'].mean()"
      ],
      "metadata": {
        "id": "xSOH9oSa5tAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train"
      ],
      "metadata": {
        "id": "SfPfGNL06gYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.loc[train['Overall Qual'] >= 5, 'target'].mean()"
      ],
      "metadata": {
        "id": "Yqq_nT0k9CjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 시각화"
      ],
      "metadata": {
        "id": "IZ4GWImiDeGr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 시각화 전 필요 없는 특성 drop"
      ],
      "metadata": {
        "id": "zC8adwr3FhDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data = train.drop(columns = ['1st Flr SF', 'Total Bsmt SF'], axis=1)\n",
        "# train_data = train.drop(columns = '1st Flr SF', axis=1)\n",
        "# train_data = train.drop(columns = 'Total Bsmt SF', axis=1)"
      ],
      "metadata": {
        "id": "cyw2C1b-FkGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 컬럼별 BoxPlot\n",
        "train.plot(kind='box', subplots=True, layout=(7, 5), figsize=(15, 21))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2zOGSxBc_4qM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "outputId": "341e1d97-a296-484c-c9b1-225b3d5a6127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1512 with 35 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bH9Wjcd7_Y-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "outputId": "aa924123-c3ef-42c2-84bf-b1422b09ae77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1080 with 25 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "plt.subplots(figsize=(15,15))\n",
        "sns.heatmap(train.corr(), mask=np.zeros_like(train.corr(), dtype=bool),\n",
        "            square=True, annot=True, cmap='Greens')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TGVgSObl_bpf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "outputId": "a6f03966-6ac8-4400-e4a3-376e0057350c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = [\n",
        "  'Overall Qual',\n",
        "  'Gr Liv Area',\n",
        "  'Garage Cars',\n",
        "  'Garage Area',\n",
        "  'Full Bath',\n",
        "  'Year Built',\n",
        "  'Year Remod/Add',\n",
        "  'Garage Yr Blt',\n",
        "  # 'sum of house',\n",
        "  # 'total of house',\n",
        "  '1st Flr SF',\n",
        "  'Total Bsmt SF',\n",
        "  'Year Gap Remod',\n",
        "  'Car Area',\n",
        "  '2nd flr SF',\n",
        "  '2nd flr',\n",
        "  'Total SF',\n",
        "  'Sum Qual',\n",
        "  'Garage InOut',\n",
        "  # 'target',\n",
        "]\n",
        "\n",
        "train_data = train[features]"
      ],
      "metadata": {
        "id": "_aPdqZ-IY97k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "plt.subplots(figsize=(20,20))\n",
        "sns.heatmap(train_data.corr(), mask=np.zeros_like(train_data.corr(), dtype=bool),\n",
        "            square=True, annot=True, cmap='Spectral')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "REomd7NpH3Dw",
        "outputId": "99a89e09-9a15-427f-bfe5-b64815cdce78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1440 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test.hist(bins=50, figsize=(20,15))\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "agA27JZQa4t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data[features]\n",
        "Y = train['target']\n",
        "test_X = test[features]\n",
        "Y = np.log1p(Y)"
      ],
      "metadata": {
        "id": "zgaORZnZB-Hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 및 test 데이터 분할\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,Y, random_state=0, test_size=0.1)"
      ],
      "metadata": {
        "id": "IjRGG65VB6Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #성지야 미안 일일히 입력하기 귀찮더라고... score 잘 쓸게.. ^^\n",
        "# score_List=[]\n",
        "\n",
        "# model = KNeighborsRegressor(n_neighbors=5).fit(x_train, y_train)\n",
        "# score_List.append(f'KNeighborsRegressor: train_score: {model.score(x_train, y_train)}, val_score: {model.score(x_test, y_test)}')\n",
        "\n",
        "# model = LinearRegression().fit(x_train, y_train)\n",
        "# score_List.append(f'LinearRegression: train_score: {model.score(x_train, y_train)}, val_score: {model.score(x_test, y_test)}')\n",
        "\n",
        "# model = Ridge(random_state=0).fit(x_train, y_train)\n",
        "# score_List.append(f'Ridge: train_score: {model.score(x_train, y_train)}, val_score: {model.score(x_test, y_test)}')\n",
        "\n",
        "# model = Lasso(random_state=0).fit(x_train, y_train)\n",
        "# score_List.append(f'Lasso: train_score: {model.score(x_train, y_train)}, val_score: {model.score(x_test, y_test)}')\n",
        "\n",
        "# model = RandomForestRegressor(random_state=0).fit(x_train, y_train)\n",
        "# score_List.append(f'RandomForestRegressor: train_score: {model.score(x_train, y_train)}, val_score: {model.score(x_test, y_test)}')\n",
        "\n",
        "# model = GradientBoostingRegressor(random_state=0).fit(x_train, y_train)\n",
        "# score_List.append(f'GradientBoostingRegressor: train_score: {model.score(x_train, y_train)}, val_score: {model.score(x_test, y_test)}')\n",
        "\n",
        "# model = XGBRegressor(random_state=0).fit(x_train, y_train)\n",
        "# score_List.append(f'XGBRegressor: train_score: {model.score(x_train, y_train)}, val_score: {model.score(x_test, y_test)}')\n",
        "\n",
        "# model = LGBMRegressor(random_state=0).fit(x_train, y_train)\n",
        "# score_List.append(f'LGBMRegressor: train_score: {model.score(x_train, y_train)}, val_score: {model.score(x_test, y_test)}')\n",
        "\n",
        "# model = AdaBoostRegressor(random_state=0).fit(x_train, y_train)\n",
        "# score_List.append(f'AdaBoostRegressor: train_score: {model.score(x_train, y_train)}, val_score: {model.score(x_test, y_test)}')\n",
        "\n",
        "# model = BaggingRegressor(random_state=0).fit(x_train, y_train)\n",
        "# score_List.append(f'BaggingRegressor: train_score: {model.score(x_train, y_train)}, val_score: {model.score(x_test, y_test)}')\n",
        "\n",
        "# score_List"
      ],
      "metadata": {
        "id": "Pt7tmc7hKvDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### scaleing"
      ],
      "metadata": {
        "id": "87z_asY_f-WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LogisticRegression(), -> continuous에러 / LogisticRegression\n",
        "models=[RandomForestRegressor(random_state=0), \n",
        "        KNeighborsRegressor(), \n",
        "        BaggingRegressor(random_state=0),\n",
        "        GradientBoostingRegressor(random_state=0), \n",
        "        XGBRegressor(random_state=0), \n",
        "        LGBMRegressor(random_state=0),\n",
        "        AdaBoostRegressor(random_state=0), LinearRegression(), \n",
        "        SVR(kernel='poly'), SVR(kernel='rbf'), \n",
        "        Lasso(random_state=0), Ridge(random_state=0),\n",
        "        CatBoostRegressor(random_state = 0, loss_function = 'MAE', verbose = 0),\n",
        "        HuberRegressor(),\n",
        "        LassoLars(),\n",
        "        NGBRegressor(random_state = 0, verbose = 0),\n",
        "        ]\n",
        "     \n",
        "model_names=['RandomForestRegressor', 'KNeighborsRegressor', 'BaggingRegressor', 'GradientBoostingRegressor', 'XGBRegressor', 'LGBMRegressor',\n",
        "             'AdaBoostRegressor', 'LinearRegression', 'SVR_poly', 'SVR_rbf', 'Lasso', 'Ridge', 'CatBoost', 'Huber', 'NGBoost',\n",
        "          ]\n",
        "rmse_list=[]\n",
        "# d={}\n",
        "for model in range (len(models)):\n",
        "    clf=models[model]\n",
        "    clf.fit(x_train,y_train)\n",
        "    test_pred=clf.predict(x_test)\n",
        "\n",
        "    k=0\n",
        "    for i in test_pred:\n",
        "      if i<0:\n",
        "        test_pred[k] = 0\n",
        "      k+=1\n",
        "    nmae = NMAE(np.expm1(test_pred), np.expm1(y_test))\n",
        "    rmse_list.append((nmae))\n",
        "\n",
        "\n",
        "for model in range(len(model_names)):\n",
        "  print('%s RMSE : \\t\\t %.20f \\n'%(model_names[model],  rmse_list[model]))\n"
      ],
      "metadata": {
        "id": "NYSZDlXMoMyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "973c0aee-bea4-4cb5-c147-600b93c87a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:05:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestRegressor RMSE : \t\t 0.10171539402818831344 \n",
            "\n",
            "KNeighborsRegressor RMSE : \t\t 0.14850335560476063401 \n",
            "\n",
            "BaggingRegressor RMSE : \t\t 0.10665292318365567070 \n",
            "\n",
            "GradientBoostingRegressor RMSE : \t\t 0.10363996357240289059 \n",
            "\n",
            "XGBRegressor RMSE : \t\t 0.10382559036878155623 \n",
            "\n",
            "LGBMRegressor RMSE : \t\t 0.09407022986708750423 \n",
            "\n",
            "AdaBoostRegressor RMSE : \t\t 0.11444180820380678298 \n",
            "\n",
            "LinearRegression RMSE : \t\t 0.10532123009569328842 \n",
            "\n",
            "SVR_poly RMSE : \t\t 0.12908662763571129850 \n",
            "\n",
            "SVR_rbf RMSE : \t\t 0.13792915495507002133 \n",
            "\n",
            "Lasso RMSE : \t\t 0.13129882775068421608 \n",
            "\n",
            "Ridge RMSE : \t\t 0.10535012950345511162 \n",
            "\n",
            "CatBoost RMSE : \t\t 0.09898156964581693307 \n",
            "\n",
            "Huber RMSE : \t\t 0.14152810949343783142 \n",
            "\n",
            "NGBoost RMSE : \t\t 0.29861282098079999781 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [02:05:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
        "# RandomForestRegressor RMSE : \t\t 0.09069880236469518575 \n",
        "\n",
        "# KNeighborsRegressor RMSE : \t\t 0.11819427867352659545 \n",
        "\n",
        "# BaggingRegressor RMSE : \t\t 0.09612379785058719484 \n",
        "\n",
        "# GradientBoostingRegressor RMSE : \t\t 0.07851876592077081107 \n",
        "\n",
        "# XGBRegressor RMSE : \t\t 0.08010241511372277745 \n",
        "\n",
        "# LGBMRegressor RMSE : \t\t 0.09491340054047928132 \n",
        "\n",
        "# AdaBoostRegressor RMSE : \t\t 0.12876277086604870359 \n",
        "\n",
        "# LinearRegression RMSE : \t\t 0.08396874745053264921 \n",
        "\n",
        "# SVR_poly RMSE : \t\t 0.09724084919442893549 \n",
        "\n",
        "# SVR_rbf RMSE : \t\t 0.11632414037532801121 \n",
        "\n",
        "# Lasso RMSE : \t\t 0.10897605278861685618 \n",
        "\n",
        "# Ridge RMSE : \t\t 0.08395944187368885314 \n",
        "\n",
        "# RandomForestRegressor RMSE : \t\t 0.08601856191396299589 \n",
        "\n",
        "# KNeighborsRegressor RMSE : \t\t 0.13375350448868181252 \n",
        "\n",
        "# BaggingRegressor RMSE : \t\t 0.09045448049870306872 \n",
        "\n",
        "# GradientBoostingRegressor RMSE : \t\t 0.08539702618551645030 \n",
        "\n",
        "# XGBRegressor RMSE : \t\t 0.08045848406690736532 \n",
        "\n",
        "# LGBMRegressor RMSE : \t\t 0.08646562548660954861 \n",
        "\n",
        "# AdaBoostRegressor RMSE : \t\t 0.11907937689784149626 \n",
        "\n",
        "# LinearRegression RMSE : \t\t 0.08340941626720058122 \n",
        "\n",
        "# SVR_poly RMSE : \t\t 0.10605971642097161700 \n",
        "\n",
        "# SVR_rbf RMSE : \t\t 0.11996503575447800549 \n",
        "\n",
        "# Lasso RMSE : \t\t 0.11099385154192795144 \n",
        "\n",
        "# Ridge RMSE : \t\t 0.08340524786092293197 \n",
        "\n",
        "# CatBoost RMSE : \t\t 0.08084239853910672735 \n",
        "\n",
        "# Huber RMSE : \t\t 0.12255893738714239427 \n",
        "\n",
        "# NGBoost RMSE : \t\t 0.08416104492773733570 \n"
      ],
      "metadata": {
        "id": "zJeT0toijL7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_gbm = GradientBoostingRegressor(random_state=23)\n",
        "parameters = {\n",
        "    \"n_estimators\" : [100,110,120,130,140,150,160,170,180,190,200],\n",
        "    'max_depth' : [3],\n",
        "    'learning_rate' : [0.1],\n",
        "    }\n",
        "\n",
        "#SVR 모델 Grid Search , 파라메타들은 위에서 설정한 파라메타\n",
        "#verbose = 2 -> Grid Search 반복시 하이퍼 파라메타별 메시지를 화면에 출력 \n",
        "#cv=5 5번의 교차검증.\n",
        "grid = GridSearchCV(model_gbm, parameters, verbose=2, cv=5)\n",
        "grid.fit(X, Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGZqgm26DG_2",
        "outputId": "ffc4c013-be53-41e1-c859-46fbb1522c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 11 candidates, totalling 55 fits\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   0.3s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.3s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.3s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=110; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=120; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=130; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.4s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=140; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=150; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=160; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=170; total time=   0.5s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=180; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=190; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.6s\n",
            "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   0.6s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=GradientBoostingRegressor(random_state=23),\n",
              "             param_grid={'learning_rate': [0.1], 'max_depth': [3],\n",
              "                         'n_estimators': [100, 110, 120, 130, 140, 150, 160,\n",
              "                                          170, 180, 190, 200]},\n",
              "             verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_params_"
      ],
      "metadata": {
        "id": "AC0z7RI1Cnlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc390953-02a5-4713-a7e9-96fdc1e7763d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_gbm = GradientBoostingRegressor(random_state=0).fit(x_train, y_train)\n",
        "model_gbm.score(x_train ,y_train), model_gbm.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "6vzFabTWDRNK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29071057-e481-4eb3-fb02-501b5b12be0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9259033210953017, 0.9001780444971581)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_gbm.predict(x_test)\n",
        "NMAE(np.expm1(test_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "id": "g1WueY4pKbZR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301533ba-e4c6-4c3f-a58e-8a584a939aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08581570665773668"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_gbm = GradientBoostingRegressor(random_state=0, n_estimators=400, max_depth=2, learning_rate=0.05).fit(x_train, y_train)\n",
        "model_gbm.score(x_train ,y_train), model_gbm.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "C7ddzSneDE2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f256f4bc-df27-479e-8304-a7b19e93bd8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9166933772751572, 0.901000552867645)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_gbm.predict(x_test)\n",
        "NMAE(np.expm1(test_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "id": "pfzQKs1JKRsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15bb1397-96fa-4c2e-c370-9d7e38e42250"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08183153526764818"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "Vc1PL5TXIQJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_xgb = XGBRegressor(random_state=0)\n",
        "parameters = {\n",
        "    # \"n_estimators\" : [80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250],\n",
        "    #                   310,320,330,340,350,360,400,500,600,700, 800,900,1000],\n",
        "    # \"n_estimators\" : [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000],        \n",
        "    'max_depth' : [2,3,4,5],\n",
        "    # 'min_child_samples': [1,2,3,4,5] ,\n",
        "    # 'num_leaves': [2,3,4],\n",
        "    'n_jobs' : [-1],\n",
        "    'reg_lambda' : [1,2,3,4,5,6],\n",
        "    'learning_rate' : [0.1, 0.05, 0.01],\n",
        "    }\n",
        "    \n",
        "#verbose = 2 -> Grid Search 반복시 하이퍼 파라메타별 메시지를 화면에 출력 \n",
        "#cv=5 5번의 교차검증.\n",
        "grid = GridSearchCV(model_xgb, parameters, verbose=2, cv=5, scoring='neg_mean_absolute_error')\n",
        "grid.fit(X, Y)\n"
      ],
      "metadata": {
        "id": "J0X75LTmDWcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5034c663-d807-4ed9-f118-7d1c1c93ae9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
            "[12:14:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:14:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:14:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:14:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:14:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:14:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:14:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:14:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:14:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:14:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:14:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:14:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:14:57] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:14:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:14:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:14:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:14:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:14:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:14:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:14:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:14:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:14:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:14:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:14:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:14:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:14:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:14:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:14:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:14:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:14:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:14:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:14:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:14:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:14:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:14:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:14:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.1, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.05, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=2, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.0s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=2; total time=   0.0s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=3, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=4, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=1; total time=   0.1s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.0s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.0s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.0s\n",
            "[12:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.0s\n",
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[CV] END learning_rate=0.01, max_depth=5, n_jobs=-1, reg_lambda=6; total time=   0.0s\n",
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=XGBRegressor(),\n",
              "             param_grid={'learning_rate': [0.1, 0.05, 0.01],\n",
              "                         'max_depth': [2, 3, 4, 5], 'n_jobs': [-1],\n",
              "                         'reg_lambda': [1, 2, 3, 4, 5, 6]},\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_params_"
      ],
      "metadata": {
        "id": "Xdjl2hLvIbSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc514b85-434a-4bc7-bf29-637e83532c61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.1, 'max_depth': 3, 'n_jobs': -1, 'reg_lambda': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_xgb = XGBRegressor(n_jobs = -1,random_state=0).fit(x_train, y_train)\n",
        "model_xgb.score(x_train, y_train) , model_xgb.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "i1VaaLJdImbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5066c3a8-b02e-4fb1-f0bb-8fec1c9bc034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9165486590349694, 0.9023246812191212)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_xgb.predict(x_test)\n",
        "NMAE(np.expm1(test_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "id": "C3CMcxFOKd0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8213ab96-fec5-4efb-fd88-5f2b9f61eaee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08068061066172202"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_xgb = XGBRegressor(\n",
        "    n_estimators=200, n_jobs = -1, max_depth=3, reg_lambda=5,learning_rate=0.1, random_state=0).fit(x_train, y_train)\n",
        "model_xgb.score(x_train, y_train) , model_xgb.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "exVsaGdHIrQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63cf6da2-7cf9-4e23-dbc9-467149d919ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12:15:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9276301720570299, 0.9060974980746915)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_xgb.predict(x_test)\n",
        "NMAE(np.expm1(test_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "id": "NQWH2GFRJizL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4d6a53b-c133-4df3-a991-7c40360c5290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07790116937293626"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LGBM"
      ],
      "metadata": {
        "id": "FYtgkByEIy0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "    \"n_estimators\" : [80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300,],\n",
        "    # 'num_leaves': [2,3,4,5,6,7,8,9,10],\n",
        "    'reg_lambda' : [2,3,4,5,6],\n",
        "    'n_jobs' : [-1],\n",
        "    'learning_rate': [0.1, 0.05],\n",
        "    }\n",
        "    \n",
        "#verbose = 2 -> Grid Search 반복시 하이퍼 파라메타별 메시지를 화면에 출력 \n",
        "#cv=5 5번의 교차검증.\n",
        "grid = GridSearchCV(LGBMRegressor(random_state=0), parameters, verbose=2, cv=5)\n",
        "grid.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "DOJEy8vHKgqj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd703b1a-9552-4ed3-8b30-8e55b1256b9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 230 candidates, totalling 1150 fits\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=80, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=90, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=100, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=110, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=120, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=130, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=140, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=150, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=160, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=170, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=5; total time=   0.9s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=180, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=190, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=200, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=210, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=220, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=230, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=240, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=250, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=260, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=270, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=280, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=2; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=2; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=3; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=3; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=3; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=3; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=4; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=4; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=6; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=290, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=2; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=2; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=2; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=2; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=2; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=3; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=3; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=3; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=3; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=4; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=4; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=4; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=4; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=5; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=5; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=5; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=5; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=5; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=6; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=6; total time=   0.4s\n",
            "[CV] END learning_rate=0.1, n_estimators=300, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=80, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=90, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=100, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=110, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=3; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=120, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=2; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=3; total time=   0.5s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=3; total time=   0.5s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=4; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=5; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=130, n_jobs=-1, reg_lambda=6; total time=   0.1s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=140, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=150, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=160, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=170, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=180, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=190, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=200, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=2; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=3; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=210, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=4; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=5; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=220, n_jobs=-1, reg_lambda=6; total time=   0.2s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=230, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=240, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=250, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=260, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=270, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=2; total time=   0.4s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=280, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=5; total time=   0.4s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=290, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=2; total time=   0.4s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=2; total time=   0.4s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=2; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=3; total time=   0.4s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=3; total time=   1.0s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=3; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=3; total time=   0.4s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=4; total time=   0.4s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=4; total time=   0.4s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=4; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=4; total time=   0.4s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=5; total time=   0.4s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=5; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=5; total time=   0.4s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=5; total time=   0.4s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=6; total time=   0.3s\n",
            "[CV] END learning_rate=0.05, n_estimators=300, n_jobs=-1, reg_lambda=6; total time=   0.3s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=LGBMRegressor(random_state=0),\n",
              "             param_grid={'learning_rate': [0.1, 0.05],\n",
              "                         'n_estimators': [80, 90, 100, 110, 120, 130, 140, 150,\n",
              "                                          160, 170, 180, 190, 200, 210, 220,\n",
              "                                          230, 240, 250, 260, 270, 280, 290,\n",
              "                                          300],\n",
              "                         'n_jobs': [-1], 'reg_lambda': [2, 3, 4, 5, 6]},\n",
              "             verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_params_"
      ],
      "metadata": {
        "id": "gkBF4lcmMGh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442d87f8-f27a-45b6-dc26-06528ffedbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.05, 'n_estimators': 90, 'n_jobs': -1, 'reg_lambda': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lgbm = LGBMRegressor(n_jobs = -1, random_state=0).fit(x_train, y_train)\n",
        "model_lgbm.score(x_train, y_train) , model_lgbm.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "cw38GT84MMX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a06dd9-86f7-40c0-ac05-d2c50c73cadc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9547345002255061, 0.9063003286533882)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_lgbm.predict(x_test)\n",
        "NMAE(np.expm1(test_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "id": "QJQwTi0xMQzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d415563-bd16-4e39-dca6-e27d2e267862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08732438310046432"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lgbm = LGBMRegressor(\n",
        "    n_estimators= 90, n_jobs = -1, max_depth=3, reg_lambda=5,learning_rate=0.05, random_state=0).fit(x_train, y_train)\n",
        "model_lgbm.score(x_train, y_train) , model_lgbm.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "98fdk1KyMTqq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f4cf1cf-9bcc-4dc5-b923-9549f183877b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8815197083991795, 0.892812350693564)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_lgbm.predict(x_test)\n",
        "NMAE(np.expm1(test_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "id": "9AMvgzygMYCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e156dbda-0e61-4067-d670-92f7f4c906df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09204209219649909"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ridge / Lasso는 성능이 낮음."
      ],
      "metadata": {
        "id": "fJzzP5GOS164"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import LassoLars\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {\n",
        "    \"alpha\" : [0.1, 0.001, 0.01, 0.0001,1,10,100,1000],\n",
        "    'max_iter' : [20,30,40,50,60,70,80,90,100,200,300]\n",
        "    }\n",
        "\n",
        "grid_lasso = GridSearchCV(LassoLars(random_state = 0), parameters, verbose = 2, cv=5,  scoring='neg_mean_absolute_error')\n",
        "grid_lasso.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "ysDXVDmGMsDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "966f061c-7002-4682-d23b-4fcb07086bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 88 candidates, totalling 440 fits\n",
            "[CV] END .............................alpha=0.1, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=50; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END .............................alpha=0.1, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=90; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END .............................alpha=0.1, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=20; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=20; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=20; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=20; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ...........................alpha=0.001, max_iter=20; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=30; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=30; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=30; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=30; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=30; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=40; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=40; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=40; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=40; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=40; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=50; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=50; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=50; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=50; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=50; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=60; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=60; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ...........................alpha=0.001, max_iter=60; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=60; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=60; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=70; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=70; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=70; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=70; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=70; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=80; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=80; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=80; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=80; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=80; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=90; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=90; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=90; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=90; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ...........................alpha=0.001, max_iter=90; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=100; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=100; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=100; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=100; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=100; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=200; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=200; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=200; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=200; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=200; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=300; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=300; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=300; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=300; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=20; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ............................alpha=0.01, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=60; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ............................alpha=0.01, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=90; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=100; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ...........................alpha=0.01, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=300; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=20; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=20; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=20; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=20; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=20; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ..........................alpha=0.0001, max_iter=30; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=30; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=30; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=30; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=30; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=40; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=40; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=40; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=40; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=40; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=50; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=50; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=50; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=50; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=50; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=60; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=60; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ..........................alpha=0.0001, max_iter=60; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=60; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=60; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=70; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=70; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=70; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=70; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=70; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=80; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=80; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=80; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=80; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=80; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=90; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=90; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=90; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=90; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ..........................alpha=0.0001, max_iter=90; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=100; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=100; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=100; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=100; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=100; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=200; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=200; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=200; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=200; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=200; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=300; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=300; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=300; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=300; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=300; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=20; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ...............................alpha=1, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=100; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ..............................alpha=1, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=20; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ..............................alpha=10, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=60; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ..............................alpha=10, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=100; total time=   0.0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CV] END .............................alpha=10, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=30; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END .............................alpha=100, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=70; total time=   0.0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CV] END .............................alpha=100, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=100; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ............................alpha=100, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=20; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ............................alpha=1000, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=60; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ............................alpha=1000, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=90; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=300; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=LassoLars(random_state=0),\n",
              "             param_grid={'alpha': [0.1, 0.001, 0.01, 0.0001, 1, 10, 100, 1000],\n",
              "                         'max_iter': [20, 30, 40, 50, 60, 70, 80, 90, 100, 200,\n",
              "                                      300]},\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_lasso.best_params_"
      ],
      "metadata": {
        "id": "ULVoGtkxQEgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf7b799-042a-4822-e3bd-cc7dab8912e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.0001, 'max_iter': 20}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_las = LassoLars(alpha=0.0001, max_iter=20).fit(x_train, y_train)\n",
        "model_las.score(x_train, y_train) , model_las.score(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__0xuL5_1h3h",
        "outputId": "81fe5957-936f-4666-bed7-f576f9705a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:138: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LassoLars())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "Set parameter alpha to: original_alpha * np.sqrt(n_samples). \n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8493915231104613, 0.9046685871790827)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_las.predict(x_test)\n",
        "NMAE(np.expm1(test_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_rq2GIa1esr",
        "outputId": "2b4c8df0-4c82-4b07-c7a9-cd0766437ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08366819399997963"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_las = Lasso().fit(x_train, y_train)\n",
        "model_las.score(x_train, y_train) , model_las.score(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR0wKiDk0CSq",
        "outputId": "e6d5559a-ae39-431d-dcc5-e230d7c99b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7852061987053692, 0.8389990772966317)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_las.predict(x_test)\n",
        "NMAE(np.expm1(test_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKdyYkwS0FgZ",
        "outputId": "73f30b11-91fc-489b-ca6d-2851db430453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11126720295253485"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_las = Lasso(alpha= 0.0001, max_iter = 20).fit(x_train, y_train)\n",
        "model_las.score(x_train, y_train) , model_las.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "zjIa0pBmQGuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7fd6550-a879-48dd-cf96-45b61ee8b69e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e+01, tolerance: 1.799e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8496599236445295, 0.9106674834836245)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_las.predict(x_test)\n",
        "NMAE(np.expm1(test_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "id": "bMkbkxVpQNUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a62e4e39-09df-488b-fe56-11df3feacf52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08196343497672649"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {\n",
        "    \"alpha\" : [0.1, 0.01,0.001, 0.0001,0,1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100,200,300,400,500,600,700,800,900,1000],\n",
        "    'max_iter' : [1,2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100,200,300,400]\n",
        "    }\n",
        "\n",
        "grid_ridge = GridSearchCV(Ridge(random_state = 0), parameters, verbose = 2, cv=5, scoring='neg_mean_absolute_error' )\n",
        "grid_ridge.fit(X, Y)"
      ],
      "metadata": {
        "id": "Qb0pz8_lQRt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6524c3-ac88-4119-9974-efc135731361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 726 candidates, totalling 3630 fits\n",
            "[CV] END ..............................alpha=0.1, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=0.1, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=0.1, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=0.1, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=1; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=1; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=1; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=1; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=1; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=2; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=2; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=2; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=2; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=2; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=3; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=3; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=3; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=3; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=3; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=4; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=4; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=4; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=4; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=4; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=5; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=5; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=5; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=5; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=5; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=6; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=6; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=6; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=6; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=6; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=7; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=7; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=7; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=7; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=7; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=8; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=8; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=8; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=8; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=8; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=0.01, max_iter=9; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=10; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=10; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=10; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=10; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=10; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=0.01, max_iter=90; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=400; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=400; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=400; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=400; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.01, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=1; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=1; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=1; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=1; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=1; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=2; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=2; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=2; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=2; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=2; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=3; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=3; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=3; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=3; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=3; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=4; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=4; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=4; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=4; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=4; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=5; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=5; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=5; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=5; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=5; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=6; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=6; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=6; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=6; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=6; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=7; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=7; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=7; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=7; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=7; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=8; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=8; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=8; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=8; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=8; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=9; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=9; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=9; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=9; total time=   0.0s\n",
            "[CV] END ............................alpha=0.001, max_iter=9; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=10; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=10; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=10; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=10; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=10; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=20; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=20; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=20; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=20; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=20; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=30; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=30; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=30; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=30; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=30; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=40; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=40; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=40; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=40; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=40; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=50; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=50; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=50; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=50; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=50; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=60; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=60; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=60; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=60; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=60; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=70; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=70; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=70; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=70; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=70; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=80; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=80; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=80; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=80; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=80; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=90; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=90; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=90; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=90; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.001, max_iter=90; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=100; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=100; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=100; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=100; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=100; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=200; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=200; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=200; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=200; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=200; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=300; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=300; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=300; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=300; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=300; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=400; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=400; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=400; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=400; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.001, max_iter=400; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=1; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=1; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=1; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=1; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=1; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=2; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=2; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=2; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=2; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=2; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=3; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=3; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=3; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=3; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=3; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=4; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=4; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=4; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=4; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=4; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=5; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=5; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=5; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=5; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=5; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=6; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=6; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=6; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=6; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=6; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=7; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=7; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=7; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=7; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=7; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=8; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=8; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=8; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=8; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=8; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=9; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=9; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=9; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=9; total time=   0.0s\n",
            "[CV] END ...........................alpha=0.0001, max_iter=9; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=10; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=10; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=10; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=10; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=10; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=20; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=20; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=20; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=20; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=20; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=30; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=30; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=30; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=30; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=30; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=40; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=40; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=40; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=40; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=40; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=50; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=50; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=50; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=50; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=50; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=60; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=60; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=60; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=60; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=60; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=70; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=70; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=70; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=70; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=70; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=80; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=80; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=80; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=80; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=80; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=90; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=90; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=90; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=90; total time=   0.0s\n",
            "[CV] END ..........................alpha=0.0001, max_iter=90; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=100; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=100; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=100; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=100; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=100; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=200; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=200; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=200; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=200; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=200; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=300; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=300; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=300; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=300; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=300; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=400; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=400; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=400; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=400; total time=   0.0s\n",
            "[CV] END .........................alpha=0.0001, max_iter=400; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=2; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ................................alpha=0, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=5; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ................................alpha=0, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=8; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ................................alpha=0, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=0, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=20; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ...............................alpha=0, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=40; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ...............................alpha=0, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=0, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=200; total time=   0.0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CV] END ..............................alpha=0, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=400; total time=   0.0s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=8.6786e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_ridge.py:157: LinAlgWarning: Ill-conditioned matrix (rcond=2.64849e-19): result may not be accurate.\n",
            "  return linalg.solve(A, Xy, sym_pos=True, overwrite_a=True).T\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[CV] END ..............................alpha=0, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=0, max_iter=400; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=1, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=1, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=1, max_iter=400; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=2, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=2, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=2, max_iter=400; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=3, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=3, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=3, max_iter=400; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=4, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=4, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=4, max_iter=400; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=5, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=5, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=5, max_iter=400; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=6, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=6, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=6, max_iter=400; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=7, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=7, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=7, max_iter=400; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=8, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=8, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=8, max_iter=400; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=1; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=2; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=3; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=4; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=5; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=6; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=7; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=8; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=9; total time=   0.0s\n",
            "[CV] END ................................alpha=9, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=10; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=20; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=30; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=40; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=50; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=60; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=70; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=80; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=90; total time=   0.0s\n",
            "[CV] END ...............................alpha=9, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=100; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=200; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=300; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=9, max_iter=400; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=10, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=10, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=10, max_iter=400; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=20, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=20, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=20, max_iter=400; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=30, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=30, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=30, max_iter=400; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=40, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=40, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=40, max_iter=400; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=50, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=50, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=50, max_iter=400; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=60, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=60, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=60, max_iter=400; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=70, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=70, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=70, max_iter=400; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=80, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=80, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=80, max_iter=400; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=1; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=2; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=3; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=4; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=5; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=6; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=7; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=8; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=9; total time=   0.0s\n",
            "[CV] END ...............................alpha=90, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=10; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=20; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=30; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=40; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=50; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=60; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=70; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=80; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=90; total time=   0.0s\n",
            "[CV] END ..............................alpha=90, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=100; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=200; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=300; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=90, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=100, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=100, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=100, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=200, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=200, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=200, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=300, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=300, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=300, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=400, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=400, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=400, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=500, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=500, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=500, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=600, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=600, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=600, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=700, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=700, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=700, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=800, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=800, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=800, max_iter=400; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=1; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=2; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=3; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=4; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=5; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=6; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=7; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=8; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=9; total time=   0.0s\n",
            "[CV] END ..............................alpha=900, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=10; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=20; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=30; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=40; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=50; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=60; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=70; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=80; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=90; total time=   0.0s\n",
            "[CV] END .............................alpha=900, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=100; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=200; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=300; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=400; total time=   0.0s\n",
            "[CV] END ............................alpha=900, max_iter=400; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=1; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=1; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=1; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=1; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=1; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=2; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=2; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=2; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=2; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=2; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=3; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=3; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=3; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=3; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=3; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=4; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=4; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=4; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=4; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=4; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=5; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=5; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=5; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=5; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=5; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=6; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=6; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=6; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=6; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=6; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=7; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=7; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=7; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=7; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=7; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=8; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=8; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=8; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=8; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=8; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=9; total time=   0.0s\n",
            "[CV] END .............................alpha=1000, max_iter=9; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=10; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=10; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=10; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=10; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=10; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=20; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=30; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=40; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=50; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=60; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=70; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=80; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=90; total time=   0.0s\n",
            "[CV] END ............................alpha=1000, max_iter=90; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=100; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=200; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=300; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=400; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=400; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=400; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=400; total time=   0.0s\n",
            "[CV] END ...........................alpha=1000, max_iter=400; total time=   0.0s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=Ridge(random_state=0),\n",
              "             param_grid={'alpha': [0.1, 0.01, 0.001, 0.0001, 0, 1, 2, 3, 4, 5,\n",
              "                                   6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80,\n",
              "                                   90, 100, 200, 300, 400, 500, 600, 700, ...],\n",
              "                         'max_iter': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40,\n",
              "                                      50, 60, 70, 80, 90, 100, 200, 300, 400]},\n",
              "             scoring='neg_mean_absolute_error', verbose=2)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_ridge.best_params_"
      ],
      "metadata": {
        "id": "viEhZ4cWQkDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2ec575-2c45-47b6-8b2e-6fba7c11ff9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 100, 'max_iter': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ri = Ridge().fit(x_train, y_train)\n",
        "model_ri.score(x_train, y_train) , model_ri.score(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muNGEANo0otL",
        "outputId": "4baaff58-c7e1-4b85-bea5-2c691fee79f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8513222059667166, 0.9080793564128)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_ri.predict(x_test)\n",
        "NMAE(np.expm1(test_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52GL4Yr10pHA",
        "outputId": "9dcaaf66-9928-4442-9aed-ca6e04597bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08340416700779889"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ri = Ridge(alpha=1).fit(x_train, y_train)\n",
        "model_ri.score(x_train, y_train) , model_ri.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "R7xjAbCHQlJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4f96a02-c45c-4e16-e955-040fe39cdda5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8513222059667166, 0.9080793564128)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_ri.predict(x_test)\n",
        "NMAE(np.expm1(test_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "id": "FPrOEar7QpPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe0b374-f1f8-4e54-99f1-b3ebc2d08b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08340416700779889"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CatBoost"
      ],
      "metadata": {
        "id": "rwbofH69K0R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor, Pool\n",
        "model_CB = CatBoostRegressor(random_state = 0, loss_function = 'MAE', verbose = 2)\n",
        "# model_CB = CatBoostRegressor(random_state = 0, loss_function = 'MAE', verbose = 2)\n"
      ],
      "metadata": {
        "id": "5okdWx18K13C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_CB.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "ZaGA3pVXLX2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "386ed930-58bf-4732-fa65-06c603fcf93d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.2912051\ttotal: 5.01ms\tremaining: 5.01s\n",
            "2:\tlearn: 0.2775449\ttotal: 17ms\tremaining: 5.66s\n",
            "4:\tlearn: 0.2654351\ttotal: 21.6ms\tremaining: 4.29s\n",
            "6:\tlearn: 0.2544152\ttotal: 26.1ms\tremaining: 3.69s\n",
            "8:\tlearn: 0.2438234\ttotal: 30.5ms\tremaining: 3.36s\n",
            "10:\tlearn: 0.2342825\ttotal: 35.1ms\tremaining: 3.16s\n",
            "12:\tlearn: 0.2253302\ttotal: 39.6ms\tremaining: 3.01s\n",
            "14:\tlearn: 0.2175068\ttotal: 44.9ms\tremaining: 2.95s\n",
            "16:\tlearn: 0.2096445\ttotal: 50.9ms\tremaining: 2.94s\n",
            "18:\tlearn: 0.2023318\ttotal: 55.9ms\tremaining: 2.89s\n",
            "20:\tlearn: 0.1957044\ttotal: 60.8ms\tremaining: 2.83s\n",
            "22:\tlearn: 0.1895274\ttotal: 65.7ms\tremaining: 2.79s\n",
            "24:\tlearn: 0.1838005\ttotal: 70.5ms\tremaining: 2.75s\n",
            "26:\tlearn: 0.1783837\ttotal: 75.1ms\tremaining: 2.71s\n",
            "28:\tlearn: 0.1733167\ttotal: 80ms\tremaining: 2.68s\n",
            "30:\tlearn: 0.1684462\ttotal: 84.8ms\tremaining: 2.65s\n",
            "32:\tlearn: 0.1639613\ttotal: 90ms\tremaining: 2.64s\n",
            "34:\tlearn: 0.1596519\ttotal: 94.8ms\tremaining: 2.61s\n",
            "36:\tlearn: 0.1554028\ttotal: 99.9ms\tremaining: 2.6s\n",
            "38:\tlearn: 0.1517684\ttotal: 105ms\tremaining: 2.58s\n",
            "40:\tlearn: 0.1484961\ttotal: 110ms\tremaining: 2.56s\n",
            "42:\tlearn: 0.1450197\ttotal: 114ms\tremaining: 2.54s\n",
            "44:\tlearn: 0.1419540\ttotal: 119ms\tremaining: 2.52s\n",
            "46:\tlearn: 0.1388532\ttotal: 124ms\tremaining: 2.51s\n",
            "48:\tlearn: 0.1361991\ttotal: 128ms\tremaining: 2.49s\n",
            "50:\tlearn: 0.1336078\ttotal: 133ms\tremaining: 2.48s\n",
            "52:\tlearn: 0.1310916\ttotal: 138ms\tremaining: 2.46s\n",
            "54:\tlearn: 0.1288533\ttotal: 142ms\tremaining: 2.44s\n",
            "56:\tlearn: 0.1265937\ttotal: 147ms\tremaining: 2.43s\n",
            "58:\tlearn: 0.1242381\ttotal: 152ms\tremaining: 2.42s\n",
            "60:\tlearn: 0.1221517\ttotal: 157ms\tremaining: 2.42s\n",
            "62:\tlearn: 0.1204982\ttotal: 162ms\tremaining: 2.4s\n",
            "64:\tlearn: 0.1186900\ttotal: 166ms\tremaining: 2.39s\n",
            "66:\tlearn: 0.1169435\ttotal: 171ms\tremaining: 2.39s\n",
            "68:\tlearn: 0.1153886\ttotal: 176ms\tremaining: 2.38s\n",
            "70:\tlearn: 0.1137707\ttotal: 181ms\tremaining: 2.37s\n",
            "72:\tlearn: 0.1124024\ttotal: 186ms\tremaining: 2.37s\n",
            "74:\tlearn: 0.1111363\ttotal: 193ms\tremaining: 2.38s\n",
            "76:\tlearn: 0.1100730\ttotal: 201ms\tremaining: 2.4s\n",
            "78:\tlearn: 0.1090589\ttotal: 205ms\tremaining: 2.39s\n",
            "80:\tlearn: 0.1076983\ttotal: 210ms\tremaining: 2.38s\n",
            "82:\tlearn: 0.1065929\ttotal: 215ms\tremaining: 2.37s\n",
            "84:\tlearn: 0.1055577\ttotal: 222ms\tremaining: 2.39s\n",
            "86:\tlearn: 0.1044918\ttotal: 227ms\tremaining: 2.38s\n",
            "88:\tlearn: 0.1036026\ttotal: 232ms\tremaining: 2.37s\n",
            "90:\tlearn: 0.1027891\ttotal: 237ms\tremaining: 2.36s\n",
            "92:\tlearn: 0.1019945\ttotal: 242ms\tremaining: 2.36s\n",
            "94:\tlearn: 0.1013100\ttotal: 247ms\tremaining: 2.35s\n",
            "96:\tlearn: 0.1004890\ttotal: 252ms\tremaining: 2.35s\n",
            "98:\tlearn: 0.0996731\ttotal: 257ms\tremaining: 2.34s\n",
            "100:\tlearn: 0.0988591\ttotal: 262ms\tremaining: 2.33s\n",
            "102:\tlearn: 0.0983500\ttotal: 267ms\tremaining: 2.32s\n",
            "104:\tlearn: 0.0976800\ttotal: 272ms\tremaining: 2.31s\n",
            "106:\tlearn: 0.0970217\ttotal: 276ms\tremaining: 2.31s\n",
            "108:\tlearn: 0.0965430\ttotal: 281ms\tremaining: 2.29s\n",
            "110:\tlearn: 0.0960284\ttotal: 286ms\tremaining: 2.29s\n",
            "112:\tlearn: 0.0956219\ttotal: 292ms\tremaining: 2.29s\n",
            "114:\tlearn: 0.0951426\ttotal: 297ms\tremaining: 2.29s\n",
            "116:\tlearn: 0.0946118\ttotal: 302ms\tremaining: 2.28s\n",
            "118:\tlearn: 0.0941340\ttotal: 307ms\tremaining: 2.27s\n",
            "120:\tlearn: 0.0936121\ttotal: 311ms\tremaining: 2.26s\n",
            "122:\tlearn: 0.0932007\ttotal: 316ms\tremaining: 2.25s\n",
            "124:\tlearn: 0.0928457\ttotal: 322ms\tremaining: 2.25s\n",
            "126:\tlearn: 0.0924313\ttotal: 330ms\tremaining: 2.27s\n",
            "128:\tlearn: 0.0920492\ttotal: 336ms\tremaining: 2.27s\n",
            "130:\tlearn: 0.0917679\ttotal: 340ms\tremaining: 2.26s\n",
            "132:\tlearn: 0.0914678\ttotal: 345ms\tremaining: 2.25s\n",
            "134:\tlearn: 0.0911254\ttotal: 349ms\tremaining: 2.24s\n",
            "136:\tlearn: 0.0908511\ttotal: 355ms\tremaining: 2.23s\n",
            "138:\tlearn: 0.0905726\ttotal: 359ms\tremaining: 2.22s\n",
            "140:\tlearn: 0.0902953\ttotal: 364ms\tremaining: 2.22s\n",
            "142:\tlearn: 0.0901112\ttotal: 367ms\tremaining: 2.2s\n",
            "144:\tlearn: 0.0898598\ttotal: 372ms\tremaining: 2.19s\n",
            "146:\tlearn: 0.0896086\ttotal: 378ms\tremaining: 2.19s\n",
            "148:\tlearn: 0.0893373\ttotal: 388ms\tremaining: 2.21s\n",
            "150:\tlearn: 0.0892257\ttotal: 393ms\tremaining: 2.21s\n",
            "152:\tlearn: 0.0889905\ttotal: 398ms\tremaining: 2.2s\n",
            "154:\tlearn: 0.0887338\ttotal: 402ms\tremaining: 2.19s\n",
            "156:\tlearn: 0.0885372\ttotal: 407ms\tremaining: 2.19s\n",
            "158:\tlearn: 0.0883916\ttotal: 411ms\tremaining: 2.17s\n",
            "160:\tlearn: 0.0881597\ttotal: 416ms\tremaining: 2.17s\n",
            "162:\tlearn: 0.0879574\ttotal: 421ms\tremaining: 2.16s\n",
            "164:\tlearn: 0.0877443\ttotal: 425ms\tremaining: 2.15s\n",
            "166:\tlearn: 0.0874941\ttotal: 430ms\tremaining: 2.15s\n",
            "168:\tlearn: 0.0873374\ttotal: 435ms\tremaining: 2.14s\n",
            "170:\tlearn: 0.0871092\ttotal: 439ms\tremaining: 2.13s\n",
            "172:\tlearn: 0.0868744\ttotal: 444ms\tremaining: 2.12s\n",
            "174:\tlearn: 0.0867029\ttotal: 451ms\tremaining: 2.13s\n",
            "176:\tlearn: 0.0864678\ttotal: 461ms\tremaining: 2.14s\n",
            "178:\tlearn: 0.0863272\ttotal: 467ms\tremaining: 2.14s\n",
            "180:\tlearn: 0.0861347\ttotal: 472ms\tremaining: 2.13s\n",
            "182:\tlearn: 0.0859686\ttotal: 476ms\tremaining: 2.13s\n",
            "184:\tlearn: 0.0858066\ttotal: 481ms\tremaining: 2.12s\n",
            "186:\tlearn: 0.0856566\ttotal: 485ms\tremaining: 2.11s\n",
            "188:\tlearn: 0.0854885\ttotal: 491ms\tremaining: 2.1s\n",
            "190:\tlearn: 0.0853422\ttotal: 496ms\tremaining: 2.1s\n",
            "192:\tlearn: 0.0851521\ttotal: 501ms\tremaining: 2.09s\n",
            "194:\tlearn: 0.0849579\ttotal: 505ms\tremaining: 2.09s\n",
            "196:\tlearn: 0.0848405\ttotal: 511ms\tremaining: 2.08s\n",
            "198:\tlearn: 0.0846742\ttotal: 516ms\tremaining: 2.08s\n",
            "200:\tlearn: 0.0845387\ttotal: 521ms\tremaining: 2.07s\n",
            "202:\tlearn: 0.0844060\ttotal: 526ms\tremaining: 2.06s\n",
            "204:\tlearn: 0.0842925\ttotal: 531ms\tremaining: 2.06s\n",
            "206:\tlearn: 0.0840570\ttotal: 536ms\tremaining: 2.05s\n",
            "208:\tlearn: 0.0839082\ttotal: 540ms\tremaining: 2.04s\n",
            "210:\tlearn: 0.0836779\ttotal: 545ms\tremaining: 2.04s\n",
            "212:\tlearn: 0.0835206\ttotal: 550ms\tremaining: 2.03s\n",
            "214:\tlearn: 0.0833395\ttotal: 555ms\tremaining: 2.03s\n",
            "216:\tlearn: 0.0831911\ttotal: 562ms\tremaining: 2.03s\n",
            "218:\tlearn: 0.0830107\ttotal: 571ms\tremaining: 2.04s\n",
            "220:\tlearn: 0.0829022\ttotal: 579ms\tremaining: 2.04s\n",
            "222:\tlearn: 0.0826864\ttotal: 586ms\tremaining: 2.04s\n",
            "224:\tlearn: 0.0825546\ttotal: 591ms\tremaining: 2.04s\n",
            "226:\tlearn: 0.0823623\ttotal: 596ms\tremaining: 2.03s\n",
            "228:\tlearn: 0.0821399\ttotal: 601ms\tremaining: 2.02s\n",
            "230:\tlearn: 0.0819270\ttotal: 606ms\tremaining: 2.02s\n",
            "232:\tlearn: 0.0817865\ttotal: 611ms\tremaining: 2.01s\n",
            "234:\tlearn: 0.0816552\ttotal: 616ms\tremaining: 2s\n",
            "236:\tlearn: 0.0814132\ttotal: 622ms\tremaining: 2s\n",
            "238:\tlearn: 0.0813060\ttotal: 626ms\tremaining: 1.99s\n",
            "240:\tlearn: 0.0811606\ttotal: 631ms\tremaining: 1.99s\n",
            "242:\tlearn: 0.0810319\ttotal: 636ms\tremaining: 1.98s\n",
            "244:\tlearn: 0.0808615\ttotal: 641ms\tremaining: 1.98s\n",
            "246:\tlearn: 0.0807519\ttotal: 646ms\tremaining: 1.97s\n",
            "248:\tlearn: 0.0806483\ttotal: 651ms\tremaining: 1.96s\n",
            "250:\tlearn: 0.0805102\ttotal: 655ms\tremaining: 1.96s\n",
            "252:\tlearn: 0.0804707\ttotal: 660ms\tremaining: 1.95s\n",
            "254:\tlearn: 0.0803193\ttotal: 664ms\tremaining: 1.94s\n",
            "256:\tlearn: 0.0801705\ttotal: 669ms\tremaining: 1.93s\n",
            "258:\tlearn: 0.0800335\ttotal: 673ms\tremaining: 1.93s\n",
            "260:\tlearn: 0.0798979\ttotal: 678ms\tremaining: 1.92s\n",
            "262:\tlearn: 0.0797399\ttotal: 682ms\tremaining: 1.91s\n",
            "264:\tlearn: 0.0796546\ttotal: 687ms\tremaining: 1.91s\n",
            "266:\tlearn: 0.0795648\ttotal: 692ms\tremaining: 1.9s\n",
            "268:\tlearn: 0.0793737\ttotal: 696ms\tremaining: 1.89s\n",
            "270:\tlearn: 0.0792844\ttotal: 701ms\tremaining: 1.89s\n",
            "272:\tlearn: 0.0790864\ttotal: 706ms\tremaining: 1.88s\n",
            "274:\tlearn: 0.0789408\ttotal: 710ms\tremaining: 1.87s\n",
            "276:\tlearn: 0.0788464\ttotal: 717ms\tremaining: 1.87s\n",
            "278:\tlearn: 0.0787202\ttotal: 723ms\tremaining: 1.87s\n",
            "280:\tlearn: 0.0785964\ttotal: 727ms\tremaining: 1.86s\n",
            "282:\tlearn: 0.0784434\ttotal: 731ms\tremaining: 1.85s\n",
            "284:\tlearn: 0.0782772\ttotal: 736ms\tremaining: 1.84s\n",
            "286:\tlearn: 0.0781747\ttotal: 740ms\tremaining: 1.84s\n",
            "288:\tlearn: 0.0780725\ttotal: 744ms\tremaining: 1.83s\n",
            "290:\tlearn: 0.0779263\ttotal: 748ms\tremaining: 1.82s\n",
            "292:\tlearn: 0.0777883\ttotal: 753ms\tremaining: 1.82s\n",
            "294:\tlearn: 0.0776621\ttotal: 757ms\tremaining: 1.81s\n",
            "296:\tlearn: 0.0775726\ttotal: 762ms\tremaining: 1.8s\n",
            "298:\tlearn: 0.0774246\ttotal: 766ms\tremaining: 1.8s\n",
            "300:\tlearn: 0.0772782\ttotal: 775ms\tremaining: 1.8s\n",
            "302:\tlearn: 0.0771892\ttotal: 780ms\tremaining: 1.79s\n",
            "304:\tlearn: 0.0771046\ttotal: 785ms\tremaining: 1.79s\n",
            "306:\tlearn: 0.0769821\ttotal: 796ms\tremaining: 1.8s\n",
            "308:\tlearn: 0.0768766\ttotal: 807ms\tremaining: 1.8s\n",
            "310:\tlearn: 0.0767338\ttotal: 816ms\tremaining: 1.81s\n",
            "312:\tlearn: 0.0766069\ttotal: 820ms\tremaining: 1.8s\n",
            "314:\tlearn: 0.0764824\ttotal: 825ms\tremaining: 1.79s\n",
            "316:\tlearn: 0.0762727\ttotal: 830ms\tremaining: 1.79s\n",
            "318:\tlearn: 0.0761409\ttotal: 834ms\tremaining: 1.78s\n",
            "320:\tlearn: 0.0759996\ttotal: 839ms\tremaining: 1.77s\n",
            "322:\tlearn: 0.0758611\ttotal: 849ms\tremaining: 1.78s\n",
            "324:\tlearn: 0.0757407\ttotal: 861ms\tremaining: 1.79s\n",
            "326:\tlearn: 0.0755844\ttotal: 866ms\tremaining: 1.78s\n",
            "328:\tlearn: 0.0754652\ttotal: 871ms\tremaining: 1.77s\n",
            "330:\tlearn: 0.0753413\ttotal: 875ms\tremaining: 1.77s\n",
            "332:\tlearn: 0.0752609\ttotal: 879ms\tremaining: 1.76s\n",
            "334:\tlearn: 0.0750527\ttotal: 884ms\tremaining: 1.75s\n",
            "336:\tlearn: 0.0749038\ttotal: 889ms\tremaining: 1.75s\n",
            "338:\tlearn: 0.0747393\ttotal: 894ms\tremaining: 1.74s\n",
            "340:\tlearn: 0.0746516\ttotal: 901ms\tremaining: 1.74s\n",
            "342:\tlearn: 0.0745363\ttotal: 907ms\tremaining: 1.74s\n",
            "344:\tlearn: 0.0744022\ttotal: 912ms\tremaining: 1.73s\n",
            "346:\tlearn: 0.0743154\ttotal: 917ms\tremaining: 1.73s\n",
            "348:\tlearn: 0.0741786\ttotal: 922ms\tremaining: 1.72s\n",
            "350:\tlearn: 0.0740985\ttotal: 927ms\tremaining: 1.71s\n",
            "352:\tlearn: 0.0740124\ttotal: 931ms\tremaining: 1.71s\n",
            "354:\tlearn: 0.0739147\ttotal: 936ms\tremaining: 1.7s\n",
            "356:\tlearn: 0.0737951\ttotal: 941ms\tremaining: 1.69s\n",
            "358:\tlearn: 0.0737222\ttotal: 946ms\tremaining: 1.69s\n",
            "360:\tlearn: 0.0736726\ttotal: 951ms\tremaining: 1.68s\n",
            "362:\tlearn: 0.0735144\ttotal: 955ms\tremaining: 1.68s\n",
            "364:\tlearn: 0.0734139\ttotal: 961ms\tremaining: 1.67s\n",
            "366:\tlearn: 0.0733031\ttotal: 971ms\tremaining: 1.67s\n",
            "368:\tlearn: 0.0732082\ttotal: 979ms\tremaining: 1.67s\n",
            "370:\tlearn: 0.0731353\ttotal: 983ms\tremaining: 1.67s\n",
            "372:\tlearn: 0.0730001\ttotal: 987ms\tremaining: 1.66s\n",
            "374:\tlearn: 0.0729038\ttotal: 992ms\tremaining: 1.65s\n",
            "376:\tlearn: 0.0728323\ttotal: 996ms\tremaining: 1.65s\n",
            "378:\tlearn: 0.0726855\ttotal: 1s\tremaining: 1.64s\n",
            "380:\tlearn: 0.0726088\ttotal: 1s\tremaining: 1.63s\n",
            "382:\tlearn: 0.0725548\ttotal: 1.01s\tremaining: 1.63s\n",
            "384:\tlearn: 0.0724973\ttotal: 1.01s\tremaining: 1.62s\n",
            "386:\tlearn: 0.0724235\ttotal: 1.02s\tremaining: 1.61s\n",
            "388:\tlearn: 0.0722559\ttotal: 1.02s\tremaining: 1.6s\n",
            "390:\tlearn: 0.0721873\ttotal: 1.03s\tremaining: 1.6s\n",
            "392:\tlearn: 0.0720234\ttotal: 1.03s\tremaining: 1.59s\n",
            "394:\tlearn: 0.0718636\ttotal: 1.03s\tremaining: 1.58s\n",
            "396:\tlearn: 0.0717755\ttotal: 1.04s\tremaining: 1.58s\n",
            "398:\tlearn: 0.0716836\ttotal: 1.04s\tremaining: 1.57s\n",
            "400:\tlearn: 0.0715761\ttotal: 1.05s\tremaining: 1.57s\n",
            "402:\tlearn: 0.0714841\ttotal: 1.05s\tremaining: 1.56s\n",
            "404:\tlearn: 0.0714281\ttotal: 1.06s\tremaining: 1.55s\n",
            "406:\tlearn: 0.0712787\ttotal: 1.06s\tremaining: 1.55s\n",
            "408:\tlearn: 0.0711960\ttotal: 1.07s\tremaining: 1.54s\n",
            "410:\tlearn: 0.0710476\ttotal: 1.07s\tremaining: 1.54s\n",
            "412:\tlearn: 0.0709751\ttotal: 1.08s\tremaining: 1.53s\n",
            "414:\tlearn: 0.0709404\ttotal: 1.08s\tremaining: 1.53s\n",
            "416:\tlearn: 0.0708508\ttotal: 1.09s\tremaining: 1.52s\n",
            "418:\tlearn: 0.0707773\ttotal: 1.09s\tremaining: 1.51s\n",
            "420:\tlearn: 0.0706638\ttotal: 1.1s\tremaining: 1.51s\n",
            "422:\tlearn: 0.0706211\ttotal: 1.1s\tremaining: 1.5s\n",
            "424:\tlearn: 0.0705545\ttotal: 1.11s\tremaining: 1.5s\n",
            "426:\tlearn: 0.0705047\ttotal: 1.11s\tremaining: 1.49s\n",
            "428:\tlearn: 0.0704132\ttotal: 1.11s\tremaining: 1.49s\n",
            "430:\tlearn: 0.0703117\ttotal: 1.12s\tremaining: 1.48s\n",
            "432:\tlearn: 0.0702575\ttotal: 1.13s\tremaining: 1.47s\n",
            "434:\tlearn: 0.0702114\ttotal: 1.13s\tremaining: 1.47s\n",
            "436:\tlearn: 0.0701586\ttotal: 1.13s\tremaining: 1.46s\n",
            "438:\tlearn: 0.0701055\ttotal: 1.14s\tremaining: 1.46s\n",
            "440:\tlearn: 0.0700149\ttotal: 1.15s\tremaining: 1.45s\n",
            "442:\tlearn: 0.0699326\ttotal: 1.15s\tremaining: 1.45s\n",
            "444:\tlearn: 0.0698944\ttotal: 1.16s\tremaining: 1.45s\n",
            "446:\tlearn: 0.0698301\ttotal: 1.17s\tremaining: 1.44s\n",
            "448:\tlearn: 0.0696955\ttotal: 1.17s\tremaining: 1.44s\n",
            "450:\tlearn: 0.0695886\ttotal: 1.17s\tremaining: 1.43s\n",
            "452:\tlearn: 0.0695390\ttotal: 1.18s\tremaining: 1.42s\n",
            "454:\tlearn: 0.0694738\ttotal: 1.18s\tremaining: 1.42s\n",
            "456:\tlearn: 0.0693411\ttotal: 1.19s\tremaining: 1.41s\n",
            "458:\tlearn: 0.0692510\ttotal: 1.19s\tremaining: 1.41s\n",
            "460:\tlearn: 0.0691751\ttotal: 1.2s\tremaining: 1.4s\n",
            "462:\tlearn: 0.0691128\ttotal: 1.2s\tremaining: 1.39s\n",
            "464:\tlearn: 0.0690819\ttotal: 1.21s\tremaining: 1.39s\n",
            "466:\tlearn: 0.0690232\ttotal: 1.21s\tremaining: 1.38s\n",
            "468:\tlearn: 0.0689720\ttotal: 1.22s\tremaining: 1.38s\n",
            "470:\tlearn: 0.0688647\ttotal: 1.22s\tremaining: 1.37s\n",
            "472:\tlearn: 0.0688187\ttotal: 1.23s\tremaining: 1.37s\n",
            "474:\tlearn: 0.0687750\ttotal: 1.23s\tremaining: 1.36s\n",
            "476:\tlearn: 0.0686825\ttotal: 1.24s\tremaining: 1.36s\n",
            "478:\tlearn: 0.0686610\ttotal: 1.24s\tremaining: 1.35s\n",
            "480:\tlearn: 0.0686077\ttotal: 1.25s\tremaining: 1.34s\n",
            "482:\tlearn: 0.0685368\ttotal: 1.25s\tremaining: 1.34s\n",
            "484:\tlearn: 0.0684821\ttotal: 1.25s\tremaining: 1.33s\n",
            "486:\tlearn: 0.0683985\ttotal: 1.26s\tremaining: 1.33s\n",
            "488:\tlearn: 0.0683498\ttotal: 1.26s\tremaining: 1.32s\n",
            "490:\tlearn: 0.0682816\ttotal: 1.27s\tremaining: 1.31s\n",
            "492:\tlearn: 0.0682459\ttotal: 1.27s\tremaining: 1.31s\n",
            "494:\tlearn: 0.0681841\ttotal: 1.28s\tremaining: 1.3s\n",
            "496:\tlearn: 0.0680341\ttotal: 1.28s\tremaining: 1.3s\n",
            "498:\tlearn: 0.0679452\ttotal: 1.29s\tremaining: 1.29s\n",
            "500:\tlearn: 0.0679188\ttotal: 1.29s\tremaining: 1.29s\n",
            "502:\tlearn: 0.0678430\ttotal: 1.3s\tremaining: 1.28s\n",
            "504:\tlearn: 0.0677947\ttotal: 1.3s\tremaining: 1.28s\n",
            "506:\tlearn: 0.0677255\ttotal: 1.31s\tremaining: 1.27s\n",
            "508:\tlearn: 0.0676899\ttotal: 1.31s\tremaining: 1.27s\n",
            "510:\tlearn: 0.0676056\ttotal: 1.32s\tremaining: 1.26s\n",
            "512:\tlearn: 0.0675597\ttotal: 1.32s\tremaining: 1.25s\n",
            "514:\tlearn: 0.0674999\ttotal: 1.33s\tremaining: 1.25s\n",
            "516:\tlearn: 0.0674144\ttotal: 1.33s\tremaining: 1.24s\n",
            "518:\tlearn: 0.0673844\ttotal: 1.34s\tremaining: 1.24s\n",
            "520:\tlearn: 0.0673216\ttotal: 1.35s\tremaining: 1.24s\n",
            "522:\tlearn: 0.0672926\ttotal: 1.36s\tremaining: 1.24s\n",
            "524:\tlearn: 0.0672498\ttotal: 1.37s\tremaining: 1.24s\n",
            "526:\tlearn: 0.0672060\ttotal: 1.37s\tremaining: 1.23s\n",
            "528:\tlearn: 0.0671185\ttotal: 1.38s\tremaining: 1.23s\n",
            "530:\tlearn: 0.0670259\ttotal: 1.38s\tremaining: 1.22s\n",
            "532:\tlearn: 0.0669783\ttotal: 1.39s\tremaining: 1.21s\n",
            "534:\tlearn: 0.0669140\ttotal: 1.39s\tremaining: 1.21s\n",
            "536:\tlearn: 0.0668423\ttotal: 1.39s\tremaining: 1.2s\n",
            "538:\tlearn: 0.0667886\ttotal: 1.4s\tremaining: 1.2s\n",
            "540:\tlearn: 0.0667556\ttotal: 1.4s\tremaining: 1.19s\n",
            "542:\tlearn: 0.0666647\ttotal: 1.41s\tremaining: 1.19s\n",
            "544:\tlearn: 0.0666019\ttotal: 1.41s\tremaining: 1.18s\n",
            "546:\tlearn: 0.0665456\ttotal: 1.42s\tremaining: 1.17s\n",
            "548:\tlearn: 0.0664658\ttotal: 1.42s\tremaining: 1.17s\n",
            "550:\tlearn: 0.0663982\ttotal: 1.43s\tremaining: 1.16s\n",
            "552:\tlearn: 0.0662496\ttotal: 1.43s\tremaining: 1.16s\n",
            "554:\tlearn: 0.0661685\ttotal: 1.44s\tremaining: 1.15s\n",
            "556:\tlearn: 0.0660607\ttotal: 1.44s\tremaining: 1.15s\n",
            "558:\tlearn: 0.0659999\ttotal: 1.45s\tremaining: 1.15s\n",
            "560:\tlearn: 0.0659584\ttotal: 1.46s\tremaining: 1.14s\n",
            "562:\tlearn: 0.0658699\ttotal: 1.46s\tremaining: 1.14s\n",
            "564:\tlearn: 0.0658244\ttotal: 1.47s\tremaining: 1.13s\n",
            "566:\tlearn: 0.0657988\ttotal: 1.47s\tremaining: 1.13s\n",
            "568:\tlearn: 0.0657139\ttotal: 1.48s\tremaining: 1.12s\n",
            "570:\tlearn: 0.0656841\ttotal: 1.48s\tremaining: 1.11s\n",
            "572:\tlearn: 0.0656533\ttotal: 1.49s\tremaining: 1.11s\n",
            "574:\tlearn: 0.0656273\ttotal: 1.49s\tremaining: 1.1s\n",
            "576:\tlearn: 0.0655889\ttotal: 1.5s\tremaining: 1.1s\n",
            "578:\tlearn: 0.0655595\ttotal: 1.5s\tremaining: 1.09s\n",
            "580:\tlearn: 0.0655374\ttotal: 1.51s\tremaining: 1.09s\n",
            "582:\tlearn: 0.0655267\ttotal: 1.51s\tremaining: 1.08s\n",
            "584:\tlearn: 0.0654818\ttotal: 1.52s\tremaining: 1.08s\n",
            "586:\tlearn: 0.0654658\ttotal: 1.52s\tremaining: 1.07s\n",
            "588:\tlearn: 0.0654032\ttotal: 1.52s\tremaining: 1.06s\n",
            "590:\tlearn: 0.0653905\ttotal: 1.53s\tremaining: 1.06s\n",
            "592:\tlearn: 0.0653377\ttotal: 1.53s\tremaining: 1.05s\n",
            "594:\tlearn: 0.0652776\ttotal: 1.54s\tremaining: 1.05s\n",
            "596:\tlearn: 0.0652523\ttotal: 1.55s\tremaining: 1.05s\n",
            "598:\tlearn: 0.0652026\ttotal: 1.55s\tremaining: 1.04s\n",
            "600:\tlearn: 0.0651728\ttotal: 1.56s\tremaining: 1.03s\n",
            "602:\tlearn: 0.0650999\ttotal: 1.56s\tremaining: 1.03s\n",
            "604:\tlearn: 0.0650509\ttotal: 1.57s\tremaining: 1.02s\n",
            "606:\tlearn: 0.0650072\ttotal: 1.57s\tremaining: 1.02s\n",
            "608:\tlearn: 0.0649188\ttotal: 1.58s\tremaining: 1.01s\n",
            "610:\tlearn: 0.0648826\ttotal: 1.58s\tremaining: 1.01s\n",
            "612:\tlearn: 0.0648501\ttotal: 1.59s\tremaining: 1s\n",
            "614:\tlearn: 0.0647937\ttotal: 1.59s\tremaining: 997ms\n",
            "616:\tlearn: 0.0647774\ttotal: 1.6s\tremaining: 991ms\n",
            "618:\tlearn: 0.0647309\ttotal: 1.6s\tremaining: 986ms\n",
            "620:\tlearn: 0.0646497\ttotal: 1.61s\tremaining: 981ms\n",
            "622:\tlearn: 0.0646145\ttotal: 1.61s\tremaining: 975ms\n",
            "624:\tlearn: 0.0645688\ttotal: 1.62s\tremaining: 970ms\n",
            "626:\tlearn: 0.0645224\ttotal: 1.62s\tremaining: 964ms\n",
            "628:\tlearn: 0.0644817\ttotal: 1.63s\tremaining: 959ms\n",
            "630:\tlearn: 0.0644512\ttotal: 1.63s\tremaining: 954ms\n",
            "632:\tlearn: 0.0643773\ttotal: 1.64s\tremaining: 948ms\n",
            "634:\tlearn: 0.0643566\ttotal: 1.64s\tremaining: 943ms\n",
            "636:\tlearn: 0.0643133\ttotal: 1.65s\tremaining: 937ms\n",
            "638:\tlearn: 0.0642787\ttotal: 1.65s\tremaining: 932ms\n",
            "640:\tlearn: 0.0642431\ttotal: 1.65s\tremaining: 927ms\n",
            "642:\tlearn: 0.0641782\ttotal: 1.66s\tremaining: 921ms\n",
            "644:\tlearn: 0.0641600\ttotal: 1.66s\tremaining: 916ms\n",
            "646:\tlearn: 0.0641424\ttotal: 1.67s\tremaining: 910ms\n",
            "648:\tlearn: 0.0641152\ttotal: 1.67s\tremaining: 905ms\n",
            "650:\tlearn: 0.0640644\ttotal: 1.68s\tremaining: 900ms\n",
            "652:\tlearn: 0.0640456\ttotal: 1.69s\tremaining: 896ms\n",
            "654:\tlearn: 0.0640027\ttotal: 1.69s\tremaining: 890ms\n",
            "656:\tlearn: 0.0639805\ttotal: 1.69s\tremaining: 885ms\n",
            "658:\tlearn: 0.0639543\ttotal: 1.7s\tremaining: 880ms\n",
            "660:\tlearn: 0.0639091\ttotal: 1.7s\tremaining: 874ms\n",
            "662:\tlearn: 0.0638486\ttotal: 1.71s\tremaining: 869ms\n",
            "664:\tlearn: 0.0637940\ttotal: 1.71s\tremaining: 863ms\n",
            "666:\tlearn: 0.0637606\ttotal: 1.72s\tremaining: 858ms\n",
            "668:\tlearn: 0.0637168\ttotal: 1.72s\tremaining: 852ms\n",
            "670:\tlearn: 0.0636608\ttotal: 1.73s\tremaining: 849ms\n",
            "672:\tlearn: 0.0636417\ttotal: 1.75s\tremaining: 848ms\n",
            "674:\tlearn: 0.0636219\ttotal: 1.75s\tremaining: 844ms\n",
            "676:\tlearn: 0.0635277\ttotal: 1.76s\tremaining: 839ms\n",
            "678:\tlearn: 0.0634768\ttotal: 1.76s\tremaining: 833ms\n",
            "680:\tlearn: 0.0634456\ttotal: 1.77s\tremaining: 828ms\n",
            "682:\tlearn: 0.0634118\ttotal: 1.77s\tremaining: 822ms\n",
            "684:\tlearn: 0.0633855\ttotal: 1.78s\tremaining: 817ms\n",
            "686:\tlearn: 0.0633453\ttotal: 1.78s\tremaining: 811ms\n",
            "688:\tlearn: 0.0632865\ttotal: 1.78s\tremaining: 806ms\n",
            "690:\tlearn: 0.0632343\ttotal: 1.79s\tremaining: 800ms\n",
            "692:\tlearn: 0.0631920\ttotal: 1.79s\tremaining: 795ms\n",
            "694:\tlearn: 0.0631497\ttotal: 1.8s\tremaining: 790ms\n",
            "696:\tlearn: 0.0631060\ttotal: 1.8s\tremaining: 784ms\n",
            "698:\tlearn: 0.0630807\ttotal: 1.81s\tremaining: 779ms\n",
            "700:\tlearn: 0.0630281\ttotal: 1.81s\tremaining: 774ms\n",
            "702:\tlearn: 0.0629534\ttotal: 1.82s\tremaining: 768ms\n",
            "704:\tlearn: 0.0629232\ttotal: 1.82s\tremaining: 763ms\n",
            "706:\tlearn: 0.0628829\ttotal: 1.83s\tremaining: 757ms\n",
            "708:\tlearn: 0.0628482\ttotal: 1.83s\tremaining: 752ms\n",
            "710:\tlearn: 0.0628189\ttotal: 1.84s\tremaining: 747ms\n",
            "712:\tlearn: 0.0627582\ttotal: 1.84s\tremaining: 741ms\n",
            "714:\tlearn: 0.0627227\ttotal: 1.85s\tremaining: 736ms\n",
            "716:\tlearn: 0.0626965\ttotal: 1.85s\tremaining: 731ms\n",
            "718:\tlearn: 0.0626704\ttotal: 1.85s\tremaining: 725ms\n",
            "720:\tlearn: 0.0626448\ttotal: 1.86s\tremaining: 720ms\n",
            "722:\tlearn: 0.0626058\ttotal: 1.86s\tremaining: 714ms\n",
            "724:\tlearn: 0.0625641\ttotal: 1.87s\tremaining: 709ms\n",
            "726:\tlearn: 0.0625337\ttotal: 1.87s\tremaining: 704ms\n",
            "728:\tlearn: 0.0625187\ttotal: 1.88s\tremaining: 698ms\n",
            "730:\tlearn: 0.0624928\ttotal: 1.88s\tremaining: 693ms\n",
            "732:\tlearn: 0.0624595\ttotal: 1.89s\tremaining: 688ms\n",
            "734:\tlearn: 0.0624004\ttotal: 1.89s\tremaining: 683ms\n",
            "736:\tlearn: 0.0623831\ttotal: 1.9s\tremaining: 678ms\n",
            "738:\tlearn: 0.0623435\ttotal: 1.9s\tremaining: 672ms\n",
            "740:\tlearn: 0.0623225\ttotal: 1.91s\tremaining: 667ms\n",
            "742:\tlearn: 0.0622945\ttotal: 1.91s\tremaining: 662ms\n",
            "744:\tlearn: 0.0622477\ttotal: 1.92s\tremaining: 659ms\n",
            "746:\tlearn: 0.0622130\ttotal: 1.93s\tremaining: 655ms\n",
            "748:\tlearn: 0.0621681\ttotal: 1.94s\tremaining: 649ms\n",
            "750:\tlearn: 0.0620852\ttotal: 1.94s\tremaining: 644ms\n",
            "752:\tlearn: 0.0620404\ttotal: 1.95s\tremaining: 638ms\n",
            "754:\tlearn: 0.0619859\ttotal: 1.95s\tremaining: 633ms\n",
            "756:\tlearn: 0.0619198\ttotal: 1.95s\tremaining: 628ms\n",
            "758:\tlearn: 0.0618894\ttotal: 1.96s\tremaining: 622ms\n",
            "760:\tlearn: 0.0618647\ttotal: 1.96s\tremaining: 617ms\n",
            "762:\tlearn: 0.0618131\ttotal: 1.97s\tremaining: 611ms\n",
            "764:\tlearn: 0.0617510\ttotal: 1.97s\tremaining: 606ms\n",
            "766:\tlearn: 0.0617153\ttotal: 1.98s\tremaining: 601ms\n",
            "768:\tlearn: 0.0616921\ttotal: 1.98s\tremaining: 595ms\n",
            "770:\tlearn: 0.0616541\ttotal: 1.99s\tremaining: 590ms\n",
            "772:\tlearn: 0.0616301\ttotal: 1.99s\tremaining: 584ms\n",
            "774:\tlearn: 0.0615549\ttotal: 1.99s\tremaining: 579ms\n",
            "776:\tlearn: 0.0615381\ttotal: 2s\tremaining: 574ms\n",
            "778:\tlearn: 0.0614980\ttotal: 2s\tremaining: 568ms\n",
            "780:\tlearn: 0.0614325\ttotal: 2.01s\tremaining: 563ms\n",
            "782:\tlearn: 0.0614031\ttotal: 2.01s\tremaining: 558ms\n",
            "784:\tlearn: 0.0613795\ttotal: 2.02s\tremaining: 552ms\n",
            "786:\tlearn: 0.0613371\ttotal: 2.02s\tremaining: 547ms\n",
            "788:\tlearn: 0.0613289\ttotal: 2.02s\tremaining: 542ms\n",
            "790:\tlearn: 0.0612684\ttotal: 2.03s\tremaining: 537ms\n",
            "792:\tlearn: 0.0612511\ttotal: 2.03s\tremaining: 531ms\n",
            "794:\tlearn: 0.0612044\ttotal: 2.04s\tremaining: 526ms\n",
            "796:\tlearn: 0.0611384\ttotal: 2.04s\tremaining: 521ms\n",
            "798:\tlearn: 0.0610878\ttotal: 2.05s\tremaining: 516ms\n",
            "800:\tlearn: 0.0610444\ttotal: 2.05s\tremaining: 510ms\n",
            "802:\tlearn: 0.0609935\ttotal: 2.06s\tremaining: 505ms\n",
            "804:\tlearn: 0.0609675\ttotal: 2.06s\tremaining: 500ms\n",
            "806:\tlearn: 0.0609482\ttotal: 2.07s\tremaining: 495ms\n",
            "808:\tlearn: 0.0609071\ttotal: 2.07s\tremaining: 490ms\n",
            "810:\tlearn: 0.0608813\ttotal: 2.08s\tremaining: 484ms\n",
            "812:\tlearn: 0.0608443\ttotal: 2.08s\tremaining: 479ms\n",
            "814:\tlearn: 0.0607885\ttotal: 2.09s\tremaining: 474ms\n",
            "816:\tlearn: 0.0607527\ttotal: 2.09s\tremaining: 469ms\n",
            "818:\tlearn: 0.0607242\ttotal: 2.1s\tremaining: 463ms\n",
            "820:\tlearn: 0.0606835\ttotal: 2.1s\tremaining: 458ms\n",
            "822:\tlearn: 0.0606607\ttotal: 2.11s\tremaining: 453ms\n",
            "824:\tlearn: 0.0606130\ttotal: 2.12s\tremaining: 449ms\n",
            "826:\tlearn: 0.0605794\ttotal: 2.12s\tremaining: 444ms\n",
            "828:\tlearn: 0.0605589\ttotal: 2.13s\tremaining: 439ms\n",
            "830:\tlearn: 0.0605174\ttotal: 2.13s\tremaining: 433ms\n",
            "832:\tlearn: 0.0604648\ttotal: 2.13s\tremaining: 428ms\n",
            "834:\tlearn: 0.0604558\ttotal: 2.14s\tremaining: 423ms\n",
            "836:\tlearn: 0.0604380\ttotal: 2.14s\tremaining: 417ms\n",
            "838:\tlearn: 0.0604143\ttotal: 2.15s\tremaining: 412ms\n",
            "840:\tlearn: 0.0603327\ttotal: 2.15s\tremaining: 408ms\n",
            "842:\tlearn: 0.0602802\ttotal: 2.16s\tremaining: 403ms\n",
            "844:\tlearn: 0.0602321\ttotal: 2.17s\tremaining: 397ms\n",
            "846:\tlearn: 0.0602012\ttotal: 2.17s\tremaining: 392ms\n",
            "848:\tlearn: 0.0601608\ttotal: 2.17s\tremaining: 387ms\n",
            "850:\tlearn: 0.0601293\ttotal: 2.18s\tremaining: 382ms\n",
            "852:\tlearn: 0.0600935\ttotal: 2.18s\tremaining: 376ms\n",
            "854:\tlearn: 0.0600744\ttotal: 2.19s\tremaining: 371ms\n",
            "856:\tlearn: 0.0600513\ttotal: 2.19s\tremaining: 366ms\n",
            "858:\tlearn: 0.0600384\ttotal: 2.2s\tremaining: 361ms\n",
            "860:\tlearn: 0.0600240\ttotal: 2.2s\tremaining: 356ms\n",
            "862:\tlearn: 0.0600157\ttotal: 2.21s\tremaining: 351ms\n",
            "864:\tlearn: 0.0600098\ttotal: 2.21s\tremaining: 346ms\n",
            "866:\tlearn: 0.0599810\ttotal: 2.22s\tremaining: 340ms\n",
            "868:\tlearn: 0.0599736\ttotal: 2.22s\tremaining: 335ms\n",
            "870:\tlearn: 0.0599520\ttotal: 2.23s\tremaining: 330ms\n",
            "872:\tlearn: 0.0598943\ttotal: 2.23s\tremaining: 325ms\n",
            "874:\tlearn: 0.0598368\ttotal: 2.24s\tremaining: 319ms\n",
            "876:\tlearn: 0.0598121\ttotal: 2.24s\tremaining: 314ms\n",
            "878:\tlearn: 0.0597640\ttotal: 2.25s\tremaining: 309ms\n",
            "880:\tlearn: 0.0597122\ttotal: 2.25s\tremaining: 304ms\n",
            "882:\tlearn: 0.0596840\ttotal: 2.25s\tremaining: 299ms\n",
            "884:\tlearn: 0.0596307\ttotal: 2.26s\tremaining: 294ms\n",
            "886:\tlearn: 0.0595827\ttotal: 2.27s\tremaining: 289ms\n",
            "888:\tlearn: 0.0595113\ttotal: 2.27s\tremaining: 283ms\n",
            "890:\tlearn: 0.0594656\ttotal: 2.27s\tremaining: 278ms\n",
            "892:\tlearn: 0.0594357\ttotal: 2.28s\tremaining: 273ms\n",
            "894:\tlearn: 0.0593831\ttotal: 2.28s\tremaining: 268ms\n",
            "896:\tlearn: 0.0593632\ttotal: 2.29s\tremaining: 263ms\n",
            "898:\tlearn: 0.0593553\ttotal: 2.29s\tremaining: 258ms\n",
            "900:\tlearn: 0.0593361\ttotal: 2.3s\tremaining: 252ms\n",
            "902:\tlearn: 0.0593134\ttotal: 2.31s\tremaining: 248ms\n",
            "904:\tlearn: 0.0593025\ttotal: 2.31s\tremaining: 243ms\n",
            "906:\tlearn: 0.0592497\ttotal: 2.32s\tremaining: 238ms\n",
            "908:\tlearn: 0.0592424\ttotal: 2.32s\tremaining: 232ms\n",
            "910:\tlearn: 0.0591944\ttotal: 2.33s\tremaining: 227ms\n",
            "912:\tlearn: 0.0591377\ttotal: 2.33s\tremaining: 222ms\n",
            "914:\tlearn: 0.0591124\ttotal: 2.34s\tremaining: 217ms\n",
            "916:\tlearn: 0.0590825\ttotal: 2.34s\tremaining: 212ms\n",
            "918:\tlearn: 0.0590445\ttotal: 2.35s\tremaining: 207ms\n",
            "920:\tlearn: 0.0590301\ttotal: 2.35s\tremaining: 202ms\n",
            "922:\tlearn: 0.0590067\ttotal: 2.35s\tremaining: 197ms\n",
            "924:\tlearn: 0.0589772\ttotal: 2.36s\tremaining: 191ms\n",
            "926:\tlearn: 0.0589346\ttotal: 2.37s\tremaining: 186ms\n",
            "928:\tlearn: 0.0589065\ttotal: 2.37s\tremaining: 181ms\n",
            "930:\tlearn: 0.0588994\ttotal: 2.37s\tremaining: 176ms\n",
            "932:\tlearn: 0.0588494\ttotal: 2.38s\tremaining: 171ms\n",
            "934:\tlearn: 0.0588298\ttotal: 2.38s\tremaining: 166ms\n",
            "936:\tlearn: 0.0588115\ttotal: 2.39s\tremaining: 161ms\n",
            "938:\tlearn: 0.0587935\ttotal: 2.39s\tremaining: 155ms\n",
            "940:\tlearn: 0.0587855\ttotal: 2.4s\tremaining: 150ms\n",
            "942:\tlearn: 0.0587566\ttotal: 2.4s\tremaining: 145ms\n",
            "944:\tlearn: 0.0586850\ttotal: 2.41s\tremaining: 140ms\n",
            "946:\tlearn: 0.0586536\ttotal: 2.41s\tremaining: 135ms\n",
            "948:\tlearn: 0.0586326\ttotal: 2.42s\tremaining: 130ms\n",
            "950:\tlearn: 0.0586202\ttotal: 2.42s\tremaining: 125ms\n",
            "952:\tlearn: 0.0586150\ttotal: 2.43s\tremaining: 120ms\n",
            "954:\tlearn: 0.0585981\ttotal: 2.43s\tremaining: 115ms\n",
            "956:\tlearn: 0.0585727\ttotal: 2.44s\tremaining: 109ms\n",
            "958:\tlearn: 0.0585659\ttotal: 2.44s\tremaining: 104ms\n",
            "960:\tlearn: 0.0585503\ttotal: 2.44s\tremaining: 99.2ms\n",
            "962:\tlearn: 0.0585341\ttotal: 2.45s\tremaining: 94.1ms\n",
            "964:\tlearn: 0.0585035\ttotal: 2.45s\tremaining: 89ms\n",
            "966:\tlearn: 0.0585006\ttotal: 2.46s\tremaining: 83.9ms\n",
            "968:\tlearn: 0.0584749\ttotal: 2.46s\tremaining: 78.8ms\n",
            "970:\tlearn: 0.0584497\ttotal: 2.47s\tremaining: 73.7ms\n",
            "972:\tlearn: 0.0584286\ttotal: 2.47s\tremaining: 68.6ms\n",
            "974:\tlearn: 0.0584061\ttotal: 2.48s\tremaining: 63.5ms\n",
            "976:\tlearn: 0.0583949\ttotal: 2.48s\tremaining: 58.4ms\n",
            "978:\tlearn: 0.0583646\ttotal: 2.49s\tremaining: 53.3ms\n",
            "980:\tlearn: 0.0583215\ttotal: 2.49s\tremaining: 48.2ms\n",
            "982:\tlearn: 0.0582800\ttotal: 2.5s\tremaining: 43.2ms\n",
            "984:\tlearn: 0.0582288\ttotal: 2.5s\tremaining: 38.2ms\n",
            "986:\tlearn: 0.0582075\ttotal: 2.51s\tremaining: 33.1ms\n",
            "988:\tlearn: 0.0581848\ttotal: 2.51s\tremaining: 28ms\n",
            "990:\tlearn: 0.0581585\ttotal: 2.52s\tremaining: 22.9ms\n",
            "992:\tlearn: 0.0581376\ttotal: 2.52s\tremaining: 17.8ms\n",
            "994:\tlearn: 0.0581138\ttotal: 2.53s\tremaining: 12.7ms\n",
            "996:\tlearn: 0.0580930\ttotal: 2.53s\tremaining: 7.62ms\n",
            "998:\tlearn: 0.0580741\ttotal: 2.54s\tremaining: 2.54ms\n",
            "999:\tlearn: 0.0580711\ttotal: 2.54s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostRegressor at 0x7fef214dc890>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cb_pred = model_CB.predict(x_test)\n",
        "NMAE(np.expm1(cb_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU1ks3VjLzSd",
        "outputId": "1a7d54cb-e081-405e-d475-af62f92617b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08042006548175376"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###         NGBRegressor(random_state = 0, verbose = 0),`"
      ],
      "metadata": {
        "id": "FU1mhLqFlU-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ngb = NGBRegressor(random_state = 0, n_estimators=3000, learning_rate=0.01, verbose = 2).fit(x_train, y_train)\n",
        "model_ngb.score(x_train, y_train) , model_ngb.score(x_test, y_test)"
      ],
      "metadata": {
        "id": "EoVSL3sJlW5K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d1a71e-81cb-471d-c435-1aad9126ea0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[iter 0] loss=0.4642 val_loss=0.0000 scale=1.0000 norm=0.6343\n",
            "[iter 100] loss=-0.2487 val_loss=0.0000 scale=2.0000 norm=0.8800\n",
            "[iter 200] loss=-0.7277 val_loss=0.0000 scale=2.0000 norm=0.8477\n",
            "[iter 300] loss=-0.8792 val_loss=0.0000 scale=1.0000 norm=0.4465\n",
            "[iter 400] loss=-0.9350 val_loss=0.0000 scale=2.0000 norm=0.9120\n",
            "[iter 500] loss=-0.9686 val_loss=0.0000 scale=1.0000 norm=0.4587\n",
            "[iter 600] loss=-0.9951 val_loss=0.0000 scale=1.0000 norm=0.4562\n",
            "[iter 700] loss=-1.0181 val_loss=0.0000 scale=1.0000 norm=0.4532\n",
            "[iter 800] loss=-1.0400 val_loss=0.0000 scale=1.0000 norm=0.4495\n",
            "[iter 900] loss=-1.0628 val_loss=0.0000 scale=1.0000 norm=0.4461\n",
            "[iter 1000] loss=-1.0842 val_loss=0.0000 scale=2.0000 norm=0.8857\n",
            "[iter 1100] loss=-1.1054 val_loss=0.0000 scale=1.0000 norm=0.4401\n",
            "[iter 1200] loss=-1.1284 val_loss=0.0000 scale=0.5000 norm=0.2173\n",
            "[iter 1300] loss=-1.1498 val_loss=0.0000 scale=1.0000 norm=0.4304\n",
            "[iter 1400] loss=-1.1694 val_loss=0.0000 scale=1.0000 norm=0.4277\n",
            "[iter 1500] loss=-1.1885 val_loss=0.0000 scale=0.5000 norm=0.2123\n",
            "[iter 1600] loss=-1.2033 val_loss=0.0000 scale=1.0000 norm=0.4230\n",
            "[iter 1700] loss=-1.2220 val_loss=0.0000 scale=1.0000 norm=0.4182\n",
            "[iter 1800] loss=-1.2408 val_loss=0.0000 scale=1.0000 norm=0.4157\n",
            "[iter 1900] loss=-1.2579 val_loss=0.0000 scale=1.0000 norm=0.4134\n",
            "[iter 2000] loss=-1.2732 val_loss=0.0000 scale=1.0000 norm=0.4117\n",
            "[iter 2100] loss=-1.2908 val_loss=0.0000 scale=0.5000 norm=0.2040\n",
            "[iter 2200] loss=-1.3068 val_loss=0.0000 scale=0.5000 norm=0.2035\n",
            "[iter 2300] loss=-1.3184 val_loss=0.0000 scale=0.5000 norm=0.2030\n",
            "[iter 2400] loss=-1.3308 val_loss=0.0000 scale=1.0000 norm=0.4047\n",
            "[iter 2500] loss=-1.3419 val_loss=0.0000 scale=0.5000 norm=0.2018\n",
            "[iter 2600] loss=-1.3528 val_loss=0.0000 scale=1.0000 norm=0.4024\n",
            "[iter 2700] loss=-1.3630 val_loss=0.0000 scale=0.5000 norm=0.2004\n",
            "[iter 2800] loss=-1.3750 val_loss=0.0000 scale=1.0000 norm=0.3987\n",
            "[iter 2900] loss=-1.3816 val_loss=0.0000 scale=0.0078 norm=0.0031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-1.3819358093292216, 0.6058342702165233)"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_ngb.predict(x_test)\n",
        "NMAE(np.expm1(test_pred),np.expm1(y_test))"
      ],
      "metadata": {
        "id": "XycN3i45mZ_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "defd29ed-12f4-4329-9062-3c07d06c11b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08511486878102974"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model_ngb = NGBRegressor(random_state = 0, verbose = 0)\n",
        "# parameters = {\n",
        "#     \"n_estimators\" : [500,1000,2000,3000,4000,5000],\n",
        "#     #                   310,320,330,340,350,360,400,500,600,700, 800,900,1000],\n",
        "#     # \"n_estimators\" : [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000],        \n",
        "#         # 'min_child_samples': [1,2,3,4,5] ,\n",
        "#     # 'num_leaves': [2,3,4],\n",
        "#     # 'n_jobs' : [-1],\n",
        "#     # 'reg_lambda' : [1,2,3,4,5,6],\n",
        "#     'learning_rate' : [0.01, 0.02, 0.03, 0.04, 0.05]\n",
        "#     }\n",
        "    \n",
        "# #verbose = 2 -> Grid Search 반복시 하이퍼 파라메타별 메시지를 화면에 출력 \n",
        "# #cv=5 5번의 교차검증.\n",
        "# grid = GridSearchCV(model_ngb, parameters, verbose=2, cv=5)\n",
        "# grid.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "ehvahFSBle9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K Fold"
      ],
      "metadata": {
        "id": "XlCeHW6qyVoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "nmae_score = make_scorer(NMAE, greater_is_better=False)"
      ],
      "metadata": {
        "id": "SuJUY2KiyWzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # results = cross_val_score(XGBRegressor(n_estimators=190, n_jobs = -1, max_depth=3, reg_lambda=1,learning_rate=0.1, random_state=0), X, Y, cv=kf)\n",
        "# # results.mean() , results\n",
        "# results = cross_val_score(CatBoostRegressor(random_state = 0, loss_function = 'MAE', verbose = 0), X, Y, cv=kf)\n",
        "# results.mean(), results\n",
        "\n",
        "# results = cross_val_score(NGBRegressor(random_state = 0, n_estimators=1000, learning_rate=0.01, verbose = 2), X, Y, cv=kf)\n",
        "# results.mean(), results\n",
        "\n",
        "# results = cross_val_score(GradientBoostingRegressor(random_state=0, n_estimators=110, max_depth=3, learning_rate=0.1), X, Y, cv=kf)\n",
        "# results.mean(), results"
      ],
      "metadata": {
        "id": "kDH_meTD0OR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5jHMxv_l0m2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = X\n",
        "label = Y\n",
        "TEST_DATA = test_X\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "Gc2SQoliUXeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iter = 0\n",
        "sum = 0\n",
        "test_pred = 0\n",
        "Ri_pred = 0\n",
        "\n",
        "for train_index, val_index in kfold.split(features):\n",
        "  x_train, x_val = features.iloc[train_index], features.iloc[val_index]\n",
        "  y_train, y_val = label.iloc[train_index], label.iloc[val_index]\n",
        "\n",
        "  model = Ridge(random_state=0)\n",
        "  model.fit(x_train, y_train)\n",
        "  pred = model.predict(x_val)\n",
        "  n_iter+=1\n",
        "\n",
        "  nmae = (NMAE(np.expm1(y_val), np.expm1(pred)))\n",
        "  sum += nmae\n",
        "  train_size = x_train.shape[0]\n",
        "  test_size = x_test.shape[0]\n",
        "\n",
        "  print(n_iter , \"번째 정확도\", nmae , \"\\n\")\n",
        "\n",
        "  test_pred = model.predict(TEST_DATA)\n",
        "  Ri_pred += test_pred/10\n",
        "  \n",
        "\n",
        "\n",
        "print(\"\\n\", sum/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnqOEhoxhJ5s",
        "outputId": "c6e11b6a-c599-4dc8-8f1f-7da4b84cd5fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 번째 정확도 0.09239345053375533 \n",
            "\n",
            "2 번째 정확도 0.1071715485488495 \n",
            "\n",
            "3 번째 정확도 0.09273054869566365 \n",
            "\n",
            "4 번째 정확도 0.12745887638000816 \n",
            "\n",
            "5 번째 정확도 0.08431622361138906 \n",
            "\n",
            "6 번째 정확도 0.10551096851728317 \n",
            "\n",
            "7 번째 정확도 0.09729255167047404 \n",
            "\n",
            "8 번째 정확도 0.09222436593507763 \n",
            "\n",
            "9 번째 정확도 0.10101106564852635 \n",
            "\n",
            "10 번째 정확도 0.09930194829229874 \n",
            "\n",
            "\n",
            " 0.09994115478333257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_iter = 0\n",
        "sum = 0\n",
        "test_pred = 0\n",
        "Li_pred = 0\n",
        "\n",
        "for train_index, val_index in kfold.split(features):\n",
        "  x_train, x_val = features.iloc[train_index], features.iloc[val_index]\n",
        "  y_train, y_val = label.iloc[train_index], label.iloc[val_index]\n",
        "\n",
        "  model = LinearRegression(normalize=True)\n",
        "  model.fit(x_train, y_train)\n",
        "  pred = model.predict(x_val)\n",
        "  n_iter+=1\n",
        "\n",
        "  nmae = (NMAE(np.expm1(y_val), np.expm1(pred)))\n",
        "  sum += nmae\n",
        "  train_size = x_train.shape[0]\n",
        "  test_size = x_test.shape[0]\n",
        "\n",
        "  print(n_iter , \"번째 정확도\", nmae , \"\\n\")\n",
        "\n",
        "  test_pred = model.predict(TEST_DATA)\n",
        "  Li_pred += test_pred/10\n",
        "  \n",
        "\n",
        "\n",
        "print(\"\\n\", sum/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiogAw7S0IWu",
        "outputId": "10804c6a-4ce8-458f-aad5-07d935ebe0cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 번째 정확도 0.09339027695836645 \n",
            "\n",
            "2 번째 정확도 0.1065696346872668 \n",
            "\n",
            "3 번째 정확도 0.09427624722835193 \n",
            "\n",
            "4 번째 정확도 0.12738685485119 \n",
            "\n",
            "5 번째 정확도 0.0842892463853594 \n",
            "\n",
            "6 번째 정확도 0.10707343464546451 \n",
            "\n",
            "7 번째 정확도 0.09962633687871965 \n",
            "\n",
            "8 번째 정확도 0.09221773073301587 \n",
            "\n",
            "9 번째 정확도 0.10098422202969154 \n",
            "\n",
            "10 번째 정확도 0.09977110174026767 \n",
            "\n",
            "\n",
            " 0.10055850861376939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
            "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
            "\n",
            "from sklearn.pipeline import make_pipeline\n",
            "\n",
            "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
            "\n",
            "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
            "\n",
            "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
            "model.fit(X, y, **kwargs)\n",
            "\n",
            "\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "n_iter = 0\n",
        "sum = 0\n",
        "test_pred = 0\n",
        "las_pred = 0\n",
        "\n",
        "for train_index, val_index in kfold.split(features):\n",
        "  x_train, x_val = features.iloc[train_index], features.iloc[val_index]\n",
        "  y_train, y_val = label.iloc[train_index], label.iloc[val_index]\n",
        "\n",
        "  model = Lasso(alpha= 0.0001, max_iter = 20,random_state=0)\n",
        "  model.fit(x_train, y_train)\n",
        "  pred = model.predict(x_val)\n",
        "  n_iter+=1\n",
        "\n",
        "  nmae = (NMAE(np.expm1(y_val), np.expm1(pred)))\n",
        "  sum += nmae\n",
        "  train_size = x_train.shape[0]\n",
        "  test_size = x_test.shape[0]\n",
        "\n",
        "  print(n_iter , \"번째 정확도\", nmae , \"\\n\")\n",
        "\n",
        "  test_pred = model.predict(TEST_DATA)\n",
        "  las_pred += test_pred/10\n",
        "  \n",
        "\n",
        "\n",
        "print(\"\\n\", sum/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFuNWW5W904_",
        "outputId": "d51c59e0-833f-4505-e381-57a54a4413a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 번째 정확도 0.10462743786815633 \n",
            "\n",
            "2 번째 정확도 0.10327863036116357 \n",
            "\n",
            "3 번째 정확도 0.09734407699668735 \n",
            "\n",
            "4 번째 정확도 0.10756014221018904 \n",
            "\n",
            "5 번째 정확도 0.10254579663354119 \n",
            "\n",
            "6 번째 정확도 0.09740640727334257 \n",
            "\n",
            "7 번째 정확도 0.10745526414370601 \n",
            "\n",
            "8 번째 정확도 0.09316278396411752 \n",
            "\n",
            "9 번째 정확도 0.08377869566525384 \n",
            "\n",
            "10 번째 정확도 0.09772060408146235 \n",
            "\n",
            "\n",
            " 0.09948798391976198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e+01, tolerance: 1.821e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+01, tolerance: 1.827e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.318e+01, tolerance: 1.805e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.296e+01, tolerance: 1.787e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+01, tolerance: 1.819e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.123e+01, tolerance: 1.690e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.280e+01, tolerance: 1.759e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.316e+01, tolerance: 1.805e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.329e+01, tolerance: 1.793e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.280e+01, tolerance: 1.794e-02\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.expm1(Ri_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_5m6cpiD20Q",
        "outputId": "7aee17a5-bac9-4ec9-8a97-2176921cebef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([321614.87116436, 130329.96206978, 171335.35229064, ...,\n",
              "        91948.79676559, 179275.43669632, 143714.54616648])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "# n_iter = 0\n",
        "# sum = 0\n",
        "# test_pred = 0\n",
        "# GBR_pred = 0\n",
        "\n",
        "# for train_index, val_index in kfold.split(features):\n",
        "#   x_train, x_val = features.iloc[train_index], features.iloc[val_index]\n",
        "#   y_train, y_val = label.iloc[train_index], label.iloc[val_index]\n",
        "\n",
        "#   model = HuberRegressor()\n",
        "#   model.fit(x_train, y_train)\n",
        "#   pred = model.predict(x_val)\n",
        "#   n_iter+=1\n",
        "\n",
        "#   nmae = (NMAE(np.expm1(y_val), np.expm1(pred)))\n",
        "#   sum += nmae\n",
        "#   train_size = x_train.shape[0]\n",
        "#   test_size = x_test.shape[0]\n",
        "\n",
        "#   print(n_iter , \"번째 정확도\", nmae , \"\\n\")\n",
        "\n",
        "#   test_pred = model.predict(TEST_DATA)\n",
        "#   GBR_pred += test_pred/10\n",
        "  \n",
        "\n",
        "\n",
        "# print(\"\\n\", sum/10)"
      ],
      "metadata": {
        "id": "UV7tSV7fhfZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "n_iter = 0\n",
        "sum = 0\n",
        "test_pred = 0\n",
        "GBR_pred = 0\n",
        "\n",
        "for train_index, val_index in kfold.split(features):\n",
        "  x_train, x_val = features.iloc[train_index], features.iloc[val_index]\n",
        "  y_train, y_val = label.iloc[train_index], label.iloc[val_index]\n",
        "\n",
        "  model = GradientBoostingRegressor(random_state=0, n_estimators=500, max_depth=2, learning_rate=0.05)\n",
        "  model.fit(x_train, y_train)\n",
        "  pred = model.predict(x_val)\n",
        "  n_iter+=1\n",
        "\n",
        "  nmae = (NMAE(np.expm1(y_val), np.expm1(pred)))\n",
        "  sum += nmae\n",
        "  train_size = x_train.shape[0]\n",
        "  test_size = x_test.shape[0]\n",
        "\n",
        "  print(n_iter , \"번째 정확도\", nmae , \"\\n\")\n",
        "\n",
        "  test_pred = model.predict(TEST_DATA)\n",
        "  GBR_pred += test_pred/10\n",
        "  \n",
        "\n",
        "\n",
        "print(\"\\n\", sum/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAWlkM5NV_sP",
        "outputId": "d2aa6bf4-39da-4eb8-ef8d-0c180878d64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 번째 정확도 0.09901410647950268 \n",
            "\n",
            "2 번째 정확도 0.09571285396375741 \n",
            "\n",
            "3 번째 정확도 0.09402237576091046 \n",
            "\n",
            "4 번째 정확도 0.1011156893618522 \n",
            "\n",
            "5 번째 정확도 0.09867769285693323 \n",
            "\n",
            "6 번째 정확도 0.10391893573887806 \n",
            "\n",
            "7 번째 정확도 0.11651051334035291 \n",
            "\n",
            "8 번째 정확도 0.09574601427282964 \n",
            "\n",
            "9 번째 정확도 0.09365395093813111 \n",
            "\n",
            "10 번째 정확도 0.10385398558132215 \n",
            "\n",
            "\n",
            " 0.10022261182944699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GBR_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pEK0UTFEdOR",
        "outputId": "5a82cfa8-962c-49d2-9f75-895be4669ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12.75151168, 11.75051274, 12.05642656, ..., 11.32830777,\n",
              "       12.12381571, 11.80969049])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "n_iter = 0\n",
        "sum=0\n",
        "test_pred = 0\n",
        "XGB_pred = 0\n",
        "\n",
        "for train_index, val_index in kfold.split(features):\n",
        "  x_train, x_val = features.iloc[train_index], features.iloc[val_index]\n",
        "  y_train, y_val = label.iloc[train_index], label.iloc[val_index]\n",
        "\n",
        "  model = XGBRegressor(\n",
        "    n_estimators=200, n_jobs = -1, max_depth=3, reg_lambda=4,learning_rate=0.1, random_state=0)\n",
        "  model.fit(x_train, y_train)\n",
        "  pred = model.predict(x_val)\n",
        "  n_iter+=1\n",
        "\n",
        "  nmae = (NMAE(np.expm1(y_val), np.expm1(pred)))\n",
        "  sum += nmae\n",
        "  train_size = x_train.shape[0]\n",
        "  test_size = x_test.shape[0]\n",
        "\n",
        "  print(n_iter , \"번째 정확도\", nmae , \"\\n\")\n",
        "\n",
        "  test_pred = model.predict(TEST_DATA)\n",
        "  XGB_pred += test_pred/10\n",
        "\n",
        "\n",
        "print(\"\\n\", sum/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTmQDhOoX_-Y",
        "outputId": "e58c3c1b-b5ff-4f7b-bc30-2591a84fd06a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:18:42] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "1 번째 정확도 0.0962027773897682 \n",
            "\n",
            "[13:18:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "2 번째 정확도 0.09557248387159552 \n",
            "\n",
            "[13:18:44] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "3 번째 정확도 0.0925874258042813 \n",
            "\n",
            "[13:18:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "4 번째 정확도 0.10200242151570707 \n",
            "\n",
            "[13:18:45] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "5 번째 정확도 0.0983128655616363 \n",
            "\n",
            "[13:18:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "6 번째 정확도 0.11146096484540399 \n",
            "\n",
            "[13:18:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "7 번째 정확도 0.11479277269666333 \n",
            "\n",
            "[13:18:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "8 번째 정확도 0.09413679293644685 \n",
            "\n",
            "[13:18:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "9 번째 정확도 0.08745245535280934 \n",
            "\n",
            "[13:18:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "10 번째 정확도 0.10298884606019566 \n",
            "\n",
            "\n",
            " 0.09955098060345076\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "XGB_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeC1eEW2ESxB",
        "outputId": "e3ea5c31-67a9-4a3a-da93-dd0136202c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12.74171 , 11.770473, 12.039579, ..., 11.303676, 12.141073,\n",
              "       11.810584], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "n_iter = 0\n",
        "sum=0\n",
        "test_pred = 0\n",
        "CB_pred = 0\n",
        "\n",
        "for train_index, val_index in kfold.split(features):\n",
        "  x_train, x_val = features.iloc[train_index], features.iloc[val_index]\n",
        "  y_train, y_val = label.iloc[train_index], label.iloc[val_index]\n",
        "\n",
        "  model = (CatBoostRegressor(random_state = 0, loss_function = 'MAE', n_estimators= 1200, learning_rate=0.02, verbose = 0))\n",
        "  model.fit(x_train, y_train)\n",
        "  pred = model.predict(x_val)\n",
        "  n_iter+=1\n",
        "\n",
        "  nmae = (NMAE(np.expm1(y_val), np.expm1(pred)))\n",
        "  sum += nmae\n",
        "  train_size = x_train.shape[0]\n",
        "  test_size = x_test.shape[0]\n",
        "\n",
        "  print(n_iter , \"번째 정확도\", nmae , \"\\n\")\n",
        "\n",
        "  test_pred = model.predict(TEST_DATA)\n",
        "  CB_pred += test_pred/10\n",
        "\n",
        "\n",
        "print(\"\\n\", sum/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3QzgtMwX_i9",
        "outputId": "cf28e26f-cf6c-446f-a4dc-6f966c6e9902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 번째 정확도 0.09752553053043186 \n",
            "\n",
            "2 번째 정확도 0.0930498196604309 \n",
            "\n",
            "3 번째 정확도 0.09466179765895502 \n",
            "\n",
            "4 번째 정확도 0.09824963534876555 \n",
            "\n",
            "5 번째 정확도 0.09022938237276824 \n",
            "\n",
            "6 번째 정확도 0.10928212259188572 \n",
            "\n",
            "7 번째 정확도 0.10255137213220357 \n",
            "\n",
            "8 번째 정확도 0.0879536819950569 \n",
            "\n",
            "9 번째 정확도 0.08534322030170312 \n",
            "\n",
            "10 번째 정확도 0.08850532796212865 \n",
            "\n",
            "\n",
            " 0.09473518905543296\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
        "n_iter = 0\n",
        "sum=0\n",
        "test_pred = 0\n",
        "NGB_pred = 0\n",
        "\n",
        "for train_index, val_index in kfold.split(features):\n",
        "  x_train, x_val = features.iloc[train_index], features.iloc[val_index]\n",
        "  y_train, y_val = label.iloc[train_index], label.iloc[val_index]\n",
        "\n",
        "  model = (NGBRegressor(random_state = 0, n_estimators=600, learning_rate = 0.01,verbose = 1))\n",
        "  model.fit(x_train, y_train)\n",
        "  pred = model.predict(x_val)\n",
        "  n_iter+=1\n",
        "\n",
        "  nmae = (NMAE(np.expm1(y_val), np.expm1(pred)))\n",
        "  sum += nmae\n",
        "  train_size = x_train.shape[0]\n",
        "  test_size = x_test.shape[0]\n",
        "\n",
        "  test_pred\n",
        "\n",
        "  print(n_iter , \"번째 정확도\", nmae , \"\\n\")\n",
        "\n",
        "  test_pred = model.predict(TEST_DATA)\n",
        "  NGB_pred += test_pred/10\n",
        "\n",
        "\n",
        "print(\"\\n\", sum/10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PD3ZhTCeTIVz",
        "outputId": "0edb97e3-db15-41c2-9865-c039ef98ee1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[iter 0] loss=0.4703 val_loss=0.0000 scale=1.0000 norm=0.6324\n",
            "[iter 100] loss=-0.2395 val_loss=0.0000 scale=2.0000 norm=0.8741\n",
            "[iter 200] loss=-0.7319 val_loss=0.0000 scale=2.0000 norm=0.8380\n",
            "[iter 300] loss=-0.8947 val_loss=0.0000 scale=1.0000 norm=0.4394\n",
            "[iter 400] loss=-0.9501 val_loss=0.0000 scale=1.0000 norm=0.4496\n",
            "[iter 500] loss=-0.9840 val_loss=0.0000 scale=1.0000 norm=0.4512\n",
            "1 번째 정확도 0.10133458805031037 \n",
            "\n",
            "[iter 0] loss=0.4721 val_loss=0.0000 scale=1.0000 norm=0.6357\n",
            "[iter 100] loss=-0.2332 val_loss=0.0000 scale=2.0000 norm=0.8795\n",
            "[iter 200] loss=-0.7312 val_loss=0.0000 scale=2.0000 norm=0.8421\n",
            "[iter 300] loss=-0.8940 val_loss=0.0000 scale=1.0000 norm=0.4428\n",
            "[iter 400] loss=-0.9457 val_loss=0.0000 scale=1.0000 norm=0.4557\n",
            "[iter 500] loss=-0.9791 val_loss=0.0000 scale=1.0000 norm=0.4585\n",
            "2 번째 정확도 0.09785847022659941 \n",
            "\n",
            "[iter 0] loss=0.4660 val_loss=0.0000 scale=1.0000 norm=0.6351\n",
            "[iter 100] loss=-0.2449 val_loss=0.0000 scale=2.0000 norm=0.8834\n",
            "[iter 200] loss=-0.7314 val_loss=0.0000 scale=2.0000 norm=0.8544\n",
            "[iter 300] loss=-0.8894 val_loss=0.0000 scale=1.0000 norm=0.4516\n",
            "[iter 400] loss=-0.9462 val_loss=0.0000 scale=1.0000 norm=0.4585\n",
            "[iter 500] loss=-0.9770 val_loss=0.0000 scale=1.0000 norm=0.4635\n",
            "3 번째 정확도 0.0957157472739333 \n",
            "\n",
            "[iter 0] loss=0.4610 val_loss=0.0000 scale=1.0000 norm=0.6311\n",
            "[iter 100] loss=-0.2410 val_loss=0.0000 scale=2.0000 norm=0.8786\n",
            "[iter 200] loss=-0.7340 val_loss=0.0000 scale=2.0000 norm=0.8503\n",
            "[iter 300] loss=-0.8897 val_loss=0.0000 scale=2.0000 norm=0.8916\n",
            "[iter 400] loss=-0.9524 val_loss=0.0000 scale=1.0000 norm=0.4544\n",
            "[iter 500] loss=-0.9905 val_loss=0.0000 scale=1.0000 norm=0.4551\n",
            "4 번째 정확도 0.09969356318889715 \n",
            "\n",
            "[iter 0] loss=0.4698 val_loss=0.0000 scale=1.0000 norm=0.6364\n",
            "[iter 100] loss=-0.2339 val_loss=0.0000 scale=2.0000 norm=0.8828\n",
            "[iter 200] loss=-0.7307 val_loss=0.0000 scale=2.0000 norm=0.8504\n",
            "[iter 300] loss=-0.8879 val_loss=0.0000 scale=1.0000 norm=0.4530\n",
            "[iter 400] loss=-0.9417 val_loss=0.0000 scale=2.0000 norm=0.9280\n",
            "[iter 500] loss=-0.9790 val_loss=0.0000 scale=1.0000 norm=0.4624\n",
            "5 번째 정확도 0.09224204278035972 \n",
            "\n",
            "[iter 0] loss=0.4330 val_loss=0.0000 scale=1.0000 norm=0.6169\n",
            "[iter 100] loss=-0.2654 val_loss=0.0000 scale=2.0000 norm=0.8772\n",
            "[iter 200] loss=-0.7498 val_loss=0.0000 scale=2.0000 norm=0.8498\n",
            "[iter 300] loss=-0.9049 val_loss=0.0000 scale=2.0000 norm=0.9103\n",
            "[iter 400] loss=-0.9622 val_loss=0.0000 scale=2.0000 norm=0.9229\n",
            "[iter 500] loss=-0.9997 val_loss=0.0000 scale=1.0000 norm=0.4638\n",
            "6 번째 정확도 0.10393485857865223 \n",
            "\n",
            "[iter 0] loss=0.4531 val_loss=0.0000 scale=1.0000 norm=0.6287\n",
            "[iter 100] loss=-0.2566 val_loss=0.0000 scale=2.0000 norm=0.8743\n",
            "[iter 200] loss=-0.7490 val_loss=0.0000 scale=2.0000 norm=0.8375\n",
            "[iter 300] loss=-0.9083 val_loss=0.0000 scale=2.0000 norm=0.8785\n",
            "[iter 400] loss=-0.9601 val_loss=0.0000 scale=1.0000 norm=0.4530\n",
            "[iter 500] loss=-0.9931 val_loss=0.0000 scale=1.0000 norm=0.4561\n",
            "7 번째 정확도 0.10885365748018988 \n",
            "\n",
            "[iter 0] loss=0.4659 val_loss=0.0000 scale=1.0000 norm=0.6327\n",
            "[iter 100] loss=-0.2408 val_loss=0.0000 scale=2.0000 norm=0.8743\n",
            "[iter 200] loss=-0.7277 val_loss=0.0000 scale=2.0000 norm=0.8339\n",
            "[iter 300] loss=-0.8887 val_loss=0.0000 scale=1.0000 norm=0.4413\n",
            "[iter 400] loss=-0.9402 val_loss=0.0000 scale=2.0000 norm=0.9141\n",
            "[iter 500] loss=-0.9724 val_loss=0.0000 scale=1.0000 norm=0.4626\n",
            "8 번째 정확도 0.0885259963339801 \n",
            "\n",
            "[iter 0] loss=0.4625 val_loss=0.0000 scale=1.0000 norm=0.6315\n",
            "[iter 100] loss=-0.2197 val_loss=0.0000 scale=2.0000 norm=0.8816\n",
            "[iter 200] loss=-0.7201 val_loss=0.0000 scale=2.0000 norm=0.8460\n",
            "[iter 300] loss=-0.8843 val_loss=0.0000 scale=2.0000 norm=0.8944\n",
            "[iter 400] loss=-0.9386 val_loss=0.0000 scale=1.0000 norm=0.4546\n",
            "[iter 500] loss=-0.9746 val_loss=0.0000 scale=2.0000 norm=0.9102\n",
            "9 번째 정확도 0.09146463435182606 \n",
            "\n",
            "[iter 0] loss=0.4624 val_loss=0.0000 scale=1.0000 norm=0.6277\n",
            "[iter 100] loss=-0.2389 val_loss=0.0000 scale=2.0000 norm=0.8806\n",
            "[iter 200] loss=-0.7306 val_loss=0.0000 scale=2.0000 norm=0.8508\n",
            "[iter 300] loss=-0.8888 val_loss=0.0000 scale=1.0000 norm=0.4508\n",
            "[iter 400] loss=-0.9414 val_loss=0.0000 scale=2.0000 norm=0.9168\n",
            "[iter 500] loss=-0.9751 val_loss=0.0000 scale=2.0000 norm=0.9265\n",
            "10 번째 정확도 0.097348294487156 \n",
            "\n",
            "\n",
            " 0.09769718527519042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# total_pred = (NGB_pred + XGB_pred + CB_pred + GBR_pred + Ri_pred)/5\n",
        "total_pred = CB_pred * 0.8 + NGB_pred * 0.2\n",
        "total_pred = np.expm1(total_pred)\n",
        "total_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeHHXYr8hMIl",
        "outputId": "045a5e77-6aec-46d1-d72c-c200f0f36ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([333733.2291563 , 127709.55867221, 175627.06515057, ...,\n",
              "        81023.34564779, 183208.86699027, 137953.61591753])"
            ]
          },
          "metadata": {},
          "execution_count": 351
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rf_pred = np.zeros(target.shape[0])\n",
        "# rf_val = []\n",
        "# for n, (tr_idx, val_idx) in enumerate(kf.split(X, y)) :\n",
        "#     print(f'{n + 1} FOLD Training.....')\n",
        "#     tr_x, tr_y = X.iloc[tr_idx], y.iloc[tr_idx]\n",
        "#     val_x, val_y = X.iloc[val_idx], np.expm1(y.iloc[val_idx])\n",
        "    \n",
        "#     rf = RandomForestRegressor(random_state = 42, criterion = 'mae')\n",
        "#     rf.fit(tr_x, tr_y)\n",
        "    \n",
        "#     val_pred = np.expm1(rf.predict(val_x))\n",
        "#     val_nmae = NMAE(val_y, val_pred)\n",
        "#     rf_val.append(val_nmae)\n",
        "#     print(f'{n + 1} FOLD NMAE = {val_nmae}\\n')\n",
        "    \n",
        "#     fold_pred = rf.predict(target) / 10\n",
        "#     rf_pred += fold_pred\n",
        "# print(f'10FOLD Mean of NMAE = {np.mean(rf_val)} & std = {np.std(rf_val)}')"
      ],
      "metadata": {
        "id": "36Gyqpa7yp8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최종 제출"
      ],
      "metadata": {
        "id": "4IJwBekiTepX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_xgb = XGBRegressor(n_estimators=190, n_jobs = -1, max_depth=3, reg_lambda=1,learning_rate=0.1, random_state=0).fit(X, Y)\n",
        "# # model_gbm = GradientBoostingRegressor(random_state=0, n_estimators=90, max_depth=3, learning_rate=0.1).fit(X, Y)\n",
        "# # model_lgbm = LGBMRegressor(n_estimators= 110, n_jobs = -1, max_depth=3, reg_lambda=6,learning_rate=0.05, random_state=0).fit(X, Y)\n",
        "# # model_ri = Ridge(alpha=100).fit(X, Y)\n",
        "# # model_las = Lasso(alpha= 0.000001, max_iter = 90).fit(X, Y)\n",
        "# model_CB = CatBoostRegressor(depth = 5, random_state = 0, loss_function = 'MAE', n_estimators = 10000, learning_rate = 0.02, verbose = 0).fit(X,Y)\n",
        "\n",
        "\n",
        "# # model_xgb = XGBRegressor(n_estimators=250, n_jobs = -1, max_depth=3, reg_lambda=1,learning_rate=0.1, random_state=0).fit(x_train, y_train)\n",
        "# # # model_gbm = GradientBoostingRegressor(random_state=0, n_estimators=90, max_depth=3, learning_rate=0.1).fit(X, Y)\n",
        "# # # model_lgbm = LGBMRegressor(n_estimators= 110, n_jobs = -1, max_depth=3, reg_lambda=6,learning_rate=0.05, random_state=0).fit(X, Y)\n",
        "# # # model_ri = Ridge(alpha=100).fit(X, Y)\n",
        "# # # model_las = Lasso(alpha= 0.000001, max_iter = 90).fit(X, Y)\n",
        "# # model_CB = CatBoostRegressor(depth = 5, random_state = 0, loss_function = 'MAE', n_estimators = 10000, learning_rate = 0.02, verbose = 0).fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "DEE114fuTpqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xgb_pred = model_xgb.predict(x_test)\n",
        "# # gbm_pred = model_gbm.predict(x_test)\n",
        "# # lgbm_pred = model_lgbm.predict(x_test)\n",
        "# # ri_pred = model_ri.predict(x_test)\n",
        "# # las_pred = model_las.predict(x_test)\n",
        "# cb_pred = model_CB.predict(x_test)"
      ],
      "metadata": {
        "id": "9-5umhehUNc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# min = 100000000000\n",
        "# index= -1\n",
        "\n",
        "# for i in range(0,11):\n",
        "#   sum = cb_pred * ((float)(i/10)) + NGB_pred * (float((10-i)/10))\n",
        "  \n",
        "#   print(\"sum is : \" , (NMAE(np.expm1(sum), np.expm1(y_test))) , \"\\n\")\n",
        "#   if((NMAE(np.expm1(sum), np.expm1(y_test))) < min):\n",
        "#     min = (NMAE(np.expm1(sum), np.expm1(y_test)))\n",
        "#     index=i\n",
        "\n",
        "# print(index , \"and value is : \", min)"
      ],
      "metadata": {
        "id": "wMcAe1h-Uohb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "64783b94-680c-4676-8e44-399699fe5a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-350-17e307f5a3ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_pred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mNGB_pred\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sum is : \"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNMAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (135,) (1350,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# xgb_pred = model_xgb.predict(test_X)\n",
        "# # gbm_pred = model_gbm.predict(test_X)\n",
        "# # lgbm_pred = model_lgbm.predict(test_X)\n",
        "# # ri_pred = model_ri.predict(test_X)\n",
        "# # las_pred = model_las.predict(test_X)\n",
        "# cb_pred = model_CB.predict(test_X)"
      ],
      "metadata": {
        "id": "bqv8aBTAsG85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # test_pred = ri_pred * 0.2 + xgb_pred *0.2 + gbm_pred*0.2 + lgbm_pred * 0.2 + las_pred * 0.2\n",
        "# # test_pred = xgb_pred * 0.7 + gbm_pred*0.3 * + (Use Ex EQ) + scoring x\n",
        "\n",
        "# test_pred = xgb_pred *0.2 + cb_pred * 0.8\n",
        "# test_pred = np.expm1(test_pred)"
      ],
      "metadata": {
        "id": "LeR_bMBTsHX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_pred = pd.DataFrame(total_pred)\n",
        "total_pred = np.round(total_pred)\n",
        "total_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MWvZ3FJxiu90",
        "outputId": "e70274a2-19ac-46e5-e1fa-27d1409ec074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e4cffef5-a0c8-42f7-83a9-2e244a351935\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>333733.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>127710.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>175627.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>247750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>135946.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345</th>\n",
              "      <td>322631.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1346</th>\n",
              "      <td>124210.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1347</th>\n",
              "      <td>81023.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1348</th>\n",
              "      <td>183209.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>137954.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1350 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4cffef5-a0c8-42f7-83a9-2e244a351935')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4cffef5-a0c8-42f7-83a9-2e244a351935 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4cffef5-a0c8-42f7-83a9-2e244a351935');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             0\n",
              "0     333733.0\n",
              "1     127710.0\n",
              "2     175627.0\n",
              "3     247750.0\n",
              "4     135946.0\n",
              "...        ...\n",
              "1345  322631.0\n",
              "1346  124210.0\n",
              "1347   81023.0\n",
              "1348  183209.0\n",
              "1349  137954.0\n",
              "\n",
              "[1350 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 352
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_pred = pd.DataFrame(test_pred)\n",
        "# test_pred = np.round(test_pred)\n",
        "# test_pred"
      ],
      "metadata": {
        "id": "4AHxjhA8VViu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission = pd.read_csv('/content/data/sample_submission.csv')\n",
        "sample_submission.loc[:, 'target'] = total_pred.loc[:, 0]\n",
        "sample_submission"
      ],
      "metadata": {
        "id": "2nvjPji1bdv-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "05052dba-847b-4b1d-fc4a-4f9fb96cd624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-51729d16-f247-4c74-9dd7-65e68814683d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>333733.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>127710.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>175627.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>247750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>135946.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1345</th>\n",
              "      <td>1346</td>\n",
              "      <td>322631.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1346</th>\n",
              "      <td>1347</td>\n",
              "      <td>124210.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1347</th>\n",
              "      <td>1348</td>\n",
              "      <td>81023.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1348</th>\n",
              "      <td>1349</td>\n",
              "      <td>183209.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1349</th>\n",
              "      <td>1350</td>\n",
              "      <td>137954.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1350 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51729d16-f247-4c74-9dd7-65e68814683d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51729d16-f247-4c74-9dd7-65e68814683d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51729d16-f247-4c74-9dd7-65e68814683d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id    target\n",
              "0        1  333733.0\n",
              "1        2  127710.0\n",
              "2        3  175627.0\n",
              "3        4  247750.0\n",
              "4        5  135946.0\n",
              "...    ...       ...\n",
              "1345  1346  322631.0\n",
              "1346  1347  124210.0\n",
              "1347  1348   81023.0\n",
              "1348  1349  183209.0\n",
              "1349  1350  137954.0\n",
              "\n",
              "[1350 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 354
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#케글에 업로드하며 수치 확인하기 위해 csv 확인으로 변환.\n",
        "sample_submission.to_csv('house_11.csv', index=False)"
      ],
      "metadata": {
        "id": "h7HTdMK-dMCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# features = [\n",
        "#   'Overall Qual',\n",
        "#   'Gr Liv Area',\n",
        "#   # 'Garage Cars',\n",
        "#   'Garage Area',\n",
        "#   'Full Bath',\n",
        "#   'Year Built',\n",
        "#   'Year Remod/Add',\n",
        "#   'Garage Yr Blt',\n",
        "#   'sum of house',\n",
        "#   # '1st Flr SF',\n",
        "#   # 'Total Bsmt SF',\n",
        "  # 'target',\n",
        "#   'EQ_Ex',\n",
        "#   # 'EQ_Fa',\n",
        "#   'EQ_Gd',\n",
        "#   'EQ_TA',\n",
        "#   'KQ_Ex',\n",
        "#   # 'KQ_Fa',\n",
        "#   # 'KQ_Gd',\n",
        "#   'KQ_TA',\n",
        "#   'BQ_Ex',\n",
        "#   # 'BQ_Fa',\n",
        "#   # 'BQ_Gd',\n",
        "#   # 'BQ_Po',\t\n",
        "#   'BQ_TA',\n",
        "# ]\n",
        "# features"
      ],
      "metadata": {
        "id": "vcuqBAebePqb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}